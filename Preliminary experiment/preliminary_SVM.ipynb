{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRARIES AND LOADING DATA"
      ],
      "metadata": {
        "id": "10ZeigzXF_DN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDejsgYvehGt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import json\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import nltk\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_json('train_dataset.json',  orient=\"records\", lines = True)\n",
        "validation = pd.read_json('validation_dataset.json',  orient=\"records\", lines = True)\n",
        "test = pd.read_json('test_dataset.json',  orient=\"records\", lines = True)"
      ],
      "metadata": {
        "id": "J-F7hczigDNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BINARY CLASSIFICATION"
      ],
      "metadata": {
        "id": "Sxntwq6lGEWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRID SEARCH CV FOR PARAMETER TUNING (TRAIN+VALIDATION)\n",
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "parameters = {\n",
        "              'vect__max_features': [5000,4000,3000,2000,1000,500,5],\n",
        "              'vect__min_df': [1,3,5,10],\n",
        "              'svc__C': [0.1, 1, 10, 100, 1000],\n",
        "              'svc__gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'svc__kernel': ['linear', 'rbf'] #, 'poly', 'sigmoid', 'precomputed', 'rbf']\n",
        "              }\n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid=parameters, scoring='f1_weighted')\n",
        "\n",
        "start = time.time()\n",
        "clf.fit(train['text'], train['union_label_binary'])\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print('Best Score: %s' % clf.best_score_)\n",
        "print('Best Hyperparameters: %s' % clf.best_params_)\n",
        "#print(\"\\n\")\n",
        "#print(classification_report(validation['union_label_binary'],clf.best_estimator_.predict(validation['text'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8VLJM1Th-Qo",
        "outputId": "a8d3a7d6-4906-4cc1-91ee-d44404226887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1539.0721416473389\n",
            "Best Score: 0.6700548066263969\n",
            "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 500, 'vect__min_df': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTIONS ON TEST SET\n",
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer(min_df=5, max_features=500)), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1, gamma=0.1, C=10, kernel='rbf'))\n",
        "                  ])\n",
        "start = time.time()\n",
        "pipeline.fit(train['text'], train['union_label_binary'])\n",
        "preds = pipeline.predict(test['text'])\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print(classification_report(test['union_label_binary'],preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_3jeHnExPAF",
        "outputId": "f4d2fd79-4782-4165-9cf0-ea85ea41e9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22949862480163574\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44        15\n",
            "           1       0.76      0.83      0.79        35\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.63      0.61      0.62        50\n",
            "weighted avg       0.68      0.70      0.69        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BINARY CLASSIFICATION WITH PRE-PROCESSING"
      ],
      "metadata": {
        "id": "vSIYuR7nGMKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        " \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mORulCL2YsSU",
        "outputId": "d16490bf-6fa2-46f7-b7cf-91d85001f498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://machinelearningknowledge.ai/11-techniques-of-text-preprocessing-using-nltk-in-python/\n",
        "\n",
        "#PREPROCESSING TRAINING SET\n",
        "pre_train = copy.deepcopy(train)\n",
        "\n",
        "#Lowercasing text\n",
        "pre_train['text'] = pre_train['text'].str.lower()\n",
        "\n",
        "#Removing extra whitespaces\n",
        "def remove_whitespace(text):\n",
        "    return  \" \".join(text.split())\n",
        "\n",
        "pre_train['text'] = pre_train['text'].apply(remove_whitespace)\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "#Lemmatize\n",
        "pre_train['text'] = pre_train.text.apply(lemmatize_text)\n",
        "\n",
        "#join by whitespace\n",
        "pre_train['text'] = pre_train['text'].apply(lambda x: \" \".join(x))"
      ],
      "metadata": {
        "id": "PBrA1rmeZAgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING VALIDATION SET\n",
        "pre_validation = copy.deepcopy(validation)\n",
        "\n",
        "#Lowercasing text\n",
        "pre_validation['text'] = pre_validation['text'].str.lower()\n",
        "\n",
        "#Removing extra whitespaces\n",
        "def remove_whitespace(text):\n",
        "    return  \" \".join(text.split())\n",
        "\n",
        "pre_validation['text'] = pre_validation['text'].apply(remove_whitespace)\n",
        "\n",
        "#Lemmatize\n",
        "pre_validation['text'] = pre_validation.text.apply(lemmatize_text)\n",
        "\n",
        "#join by whitespace\n",
        "pre_validation['text'] = pre_validation['text'].apply(lambda x: \" \".join(x))"
      ],
      "metadata": {
        "id": "12nIo96XZF1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING VALIDATION SET\n",
        "pre_test = copy.deepcopy(test)\n",
        "\n",
        "#Lowercasing text\n",
        "pre_test['text'] = pre_test['text'].str.lower()\n",
        "\n",
        "#Removing extra whitespaces \n",
        "def remove_whitespace(text):\n",
        "    return  \" \".join(text.split())\n",
        "\n",
        "pre_test['text'] = pre_test['text'].apply(remove_whitespace)\n",
        "\n",
        "#Lemmatize\n",
        "pre_test['text'] = pre_test.text.apply(lemmatize_text)\n",
        "\n",
        "#join by whitespace\n",
        "pre_test['text'] = pre_test['text'].apply(lambda x: \" \".join(x))"
      ],
      "metadata": {
        "id": "X8iKzxoqyXlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRID SEARCH CV FOR PARAMETER TUNING (TRAIN+VALIDATION)\n",
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "parameters = {\n",
        "              'vect__max_features': [5000,4000,3000,2000,1000,500,5],\n",
        "              'vect__min_df': [1,3,5,10],\n",
        "              'svc__C': [0.1, 1, 10, 100, 1000],\n",
        "              'svc__gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'svc__kernel': ['linear', 'rbf'] #, 'poly', 'sigmoid', 'precomputed', 'rbf']\n",
        "              }\n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid=parameters, scoring='f1_weighted')\n",
        "\n",
        "start = time.time()\n",
        "clf.fit(pre_train['text'], pre_train['union_label_binary'])\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print('Best Score: %s' % clf.best_score_)\n",
        "print('Best Hyperparameters: %s' % clf.best_params_)\n",
        "#print(\"\\n\")\n",
        "#print(classification_report(pre_validation['union_label_binary'],clf.best_estimator_.predict(pre_validation['text'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7arrkWHGY5A",
        "outputId": "c80b826b-cecd-4b11-951e-1f6fd3843b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1525.175509929657\n",
            "Best Score: 0.6779693469131438\n",
            "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTIONS ON TEST SET\n",
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer(min_df=10, max_features=5000)), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1, gamma=0.1, C=10, kernel='rbf'))\n",
        "                  ])\n",
        "\n",
        "start = time.time()\n",
        "pipeline.fit(pre_train['text'], pre_train['union_label_binary'])\n",
        "preds = pipeline.predict(pre_test['text'])\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print(classification_report(pre_test['union_label_binary'],preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNesyraly2SY",
        "outputId": "413c4b44-c204-4747-c37c-f3b66e5dacff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21779561042785645\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44        15\n",
            "           1       0.76      0.83      0.79        35\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.63      0.61      0.62        50\n",
            "weighted avg       0.68      0.70      0.69        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MULTI-LABEL CLASSIFICATION"
      ],
      "metadata": {
        "id": "yB4BkJoDGIma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING ON VALIDATION SET\n",
        "\n",
        "results = []\n",
        "\n",
        "vect__max_features = [5000,4000,3000,2000,1000,500,5]\n",
        "vect__min_df = [1,3,5,10]\n",
        "svc__C = [0.1, 1, 10, 100, 1000]\n",
        "svc__gamma = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "svc__kernel = ['linear', 'rbf']\n",
        "\n",
        "start = time.time()\n",
        "for max_ in vect__max_features:\n",
        "  for min_ in vect__min_df:\n",
        "    for C_ in svc__C:\n",
        "      for gamma_ in svc__gamma:\n",
        "        for kernel_ in svc__kernel:\n",
        "          vectorizer = TfidfVectorizer(min_df=min_, max_features=max_)  \n",
        "          vectorizer.fit(train['text'])\n",
        "          X_train_transf = vectorizer.transform(train['text'])\n",
        "          X_val_transf = vectorizer.transform(validation['text'])\n",
        "          clf = MultiOutputClassifier(SVC(random_state=1, C=C_, kernel=kernel_, gamma = gamma_)).fit(X_train_transf, train.iloc[:, [3,4,5,6,7,8,9]])\n",
        "          predictions = clf.predict(X_val_transf)\n",
        "          F1_score = f1_score(validation.iloc[:, [3,4,5,6,7,8,9]], predictions, average = 'weighted')\n",
        "          results.append((F1_score, max_, min_, C_, gamma_, kernel_))\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)"
      ],
      "metadata": {
        "id": "9dfY9Whtr-QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fadf85-005e-4a30-ca5b-1801b8605a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1576.9810464382172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FIND BEST F1-SCORE ALONG WITH BEST PARAMETERS\n",
        "maxResult = False\n",
        "for result in results:\n",
        "  if (maxResult == False):\n",
        "    maxResult = result\n",
        "  else:\n",
        "    if result[0] >= maxResult[0]:\n",
        "      maxResult = result\n",
        "print(maxResult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxJSbHBmunuO",
        "outputId": "240c26f1-f45e-48dc-d516-1e779ae557ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.26559211539448696, 1000, 10, 10, 0.0001, 'linear')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAKE PREDICTIONS ON TEST SET WITH THE BEST PARAMETERS\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=10)  \n",
        "vectorizer.fit(train['text'])\n",
        "\n",
        "X_train_transf = vectorizer.transform(train['text'])\n",
        "X_test_transf = vectorizer.transform(test['text'])\n",
        "\n",
        "start = time.time()\n",
        "clf = MultiOutputClassifier(SVC(C=10, kernel='linear')).fit(X_train_transf, train.iloc[:, [3,4,5,6,7,8,9]])\n",
        "predictions = clf.predict(X_test_transf)\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print('AUC score: {}'.format(roc_auc_score(test.iloc[:, [3,4,5,6,7,8,9]],predictions)))\n",
        "print('\\n')\n",
        "\n",
        "label_names = ['Arbitrary Inference',\t'Black and White Thinking',\t'Catastrophizing',\t'Labeling',\t'Overgeneralization',\t'Personalization',\t'Selective Abstraction']\n",
        "\n",
        "print(classification_report(test.iloc[:, [3,4,5,6,7,8,9]], predictions, target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EToLYyWl0JH",
        "outputId": "1fd7ea42-2fdb-4acb-b72d-00e42e0fdd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4835793972015381\n",
            "AUC score: 0.5663611134471449\n",
            "\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "     Arbitrary Inference       0.29      0.40      0.33        10\n",
            "Black and White Thinking       0.00      0.00      0.00         3\n",
            "         Catastrophizing       0.27      0.17      0.21        18\n",
            "                Labeling       0.25      0.17      0.20         6\n",
            "      Overgeneralization       0.33      0.25      0.29         4\n",
            "         Personalization       0.40      0.67      0.50         3\n",
            "   Selective Abstraction       0.00      0.00      0.00         6\n",
            "\n",
            "               micro avg       0.28      0.22      0.25        50\n",
            "               macro avg       0.22      0.24      0.22        50\n",
            "            weighted avg       0.24      0.22      0.22        50\n",
            "             samples avg       0.16      0.15      0.14        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MULTI-LABEL CLASSIFICATION WITH PRE-PROCESSING"
      ],
      "metadata": {
        "id": "d9JhCkkDGop3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING ON VALIDATION SET\n",
        "\n",
        "results = []\n",
        "\n",
        "vect__max_features = [5000,4000,3000,2000,1000,500,5]\n",
        "vect__min_df = [1,3,5,10]\n",
        "svc__C = [0.1, 1, 10, 100, 1000]\n",
        "svc__gamma = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "svc__kernel = ['linear', 'rbf']\n",
        "\n",
        "start = time.time()\n",
        "for max_ in vect__max_features:\n",
        "  for min_ in vect__min_df:\n",
        "    for C_ in svc__C:\n",
        "      for gamma_ in svc__gamma:\n",
        "        for kernel_ in svc__kernel:\n",
        "          vectorizer = TfidfVectorizer(min_df=min_, max_features=max_)  \n",
        "          vectorizer.fit(pre_train['text'])\n",
        "          X_train_transf = vectorizer.transform(pre_train['text'])\n",
        "          X_val_transf = vectorizer.transform(pre_validation['text'])\n",
        "          clf = MultiOutputClassifier(SVC(random_state=1, C=C_, kernel=kernel_, gamma = gamma_)).fit(X_train_transf, pre_train.iloc[:, [3,4,5,6,7,8,9]])\n",
        "          predictions = clf.predict(X_val_transf)\n",
        "          F1_score = f1_score(pre_validation.iloc[:, [3,4,5,6,7,8,9]], predictions, average = 'weighted')\n",
        "          results.append((F1_score, max_, min_, C_, gamma_, kernel_))\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)"
      ],
      "metadata": {
        "id": "4hVrogyZuzT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d628a796-f7ce-457c-bf0a-a296ddafff9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1598.324913740158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FIND BEST F1-SCORE ALONG WITH BEST PARAMETERS\n",
        "\n",
        "maxResult = False\n",
        "for result in results:\n",
        "  if (maxResult == False):\n",
        "    maxResult = result\n",
        "  else:\n",
        "    if result[0] >= maxResult[0]:\n",
        "      maxResult = result\n",
        "print(maxResult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXrbvGD6vakS",
        "outputId": "ad585e55-a742-400d-fb9e-6a4882f797c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.2744588744588745, 500, 3, 1000, 0.1, 'rbf')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAKE PREDICTIONS ON TEST SET WITH THE BEST PARAMETERS\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=500, min_df=3)  \n",
        "vectorizer.fit(pre_train['text'])\n",
        "\n",
        "X_train_transf = vectorizer.transform(pre_train['text'])\n",
        "X_test_transf = vectorizer.transform(pre_test['text'])\n",
        "\n",
        "start = time.time()\n",
        "clf = MultiOutputClassifier(SVC(C=1000, kernel='rbf', gamma = 0.1)).fit(X_train_transf, train.iloc[:, [3,4,5,6,7,8,9]])\n",
        "predictions = clf.predict(X_test_transf)\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)\n",
        "print('AUC score: {}'.format(roc_auc_score(pre_test.iloc[:, [3,4,5,6,7,8,9]],predictions)))\n",
        "print('\\n')\n",
        "\n",
        "label_names = ['Arbitrary Inference',\t'Black and White Thinking',\t'Catastrophizing',\t'Labeling',\t'Overgeneralization',\t'Personalization',\t'Selective Abstraction']\n",
        "\n",
        "print(classification_report(pre_test.iloc[:, [3,4,5,6,7,8,9]], predictions, target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXlL2kitGsgP",
        "outputId": "d74fba35-54e9-4c60-fc39-317f7c7a9b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5074355602264404\n",
            "AUC score: 0.5381279842831647\n",
            "\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "     Arbitrary Inference       0.33      0.40      0.36        10\n",
            "Black and White Thinking       0.00      0.00      0.00         3\n",
            "         Catastrophizing       0.33      0.28      0.30        18\n",
            "                Labeling       0.33      0.17      0.22         6\n",
            "      Overgeneralization       0.00      0.00      0.00         4\n",
            "         Personalization       0.33      0.33      0.33         3\n",
            "   Selective Abstraction       0.00      0.00      0.00         6\n",
            "\n",
            "               micro avg       0.31      0.22      0.26        50\n",
            "               macro avg       0.19      0.17      0.17        50\n",
            "            weighted avg       0.25      0.22      0.23        50\n",
            "             samples avg       0.19      0.16      0.16        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "SVM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}