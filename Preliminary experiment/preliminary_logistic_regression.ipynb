{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO-9rM5M5SnG"
   },
   "source": [
    "## LOADING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srIR8fjSyLsM",
    "outputId": "a964e13e-7829-4ab6-c75e-6ff56e1af41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQm24Wq9yvnx"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train_dataset.json',  orient=\"records\", lines = True)\n",
    "validation = pd.read_json('validation_dataset.json',  orient=\"records\", lines = True)\n",
    "test = pd.read_json('test_dataset.json',  orient=\"records\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AjVNrDDC0tZY",
    "outputId": "cb2b70f7-401e-464d-fb64-435a0462a754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3a458a54-80a4-4e93-9a55-e7aefb6b2931\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>union_label</th>\n",
       "      <th>union_label_binary</th>\n",
       "      <th>Arbitrary Inference</th>\n",
       "      <th>Black and White Thinking</th>\n",
       "      <th>Catastrophizing</th>\n",
       "      <th>Labeling</th>\n",
       "      <th>Overgeneralization</th>\n",
       "      <th>Personalization</th>\n",
       "      <th>Selective Abstraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love school, getting to see friends everyday...</td>\n",
       "      <td>[Not Distorted]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys.  So I was diagnosed with Panic disor...</td>\n",
       "      <td>[Selective Abstraction]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not sure if this is the right place for th...</td>\n",
       "      <td>[Not Distorted]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are not the boss of me.  Had I written thi...</td>\n",
       "      <td>[Not Distorted]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is literally all I think about. I frequen...</td>\n",
       "      <td>[Not Distorted]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a458a54-80a4-4e93-9a55-e7aefb6b2931')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3a458a54-80a4-4e93-9a55-e7aefb6b2931 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3a458a54-80a4-4e93-9a55-e7aefb6b2931');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text              union_label  \\\n",
       "0  I love school, getting to see friends everyday...          [Not Distorted]   \n",
       "1  Hey guys.  So I was diagnosed with Panic disor...  [Selective Abstraction]   \n",
       "2  I'm not sure if this is the right place for th...          [Not Distorted]   \n",
       "3  You are not the boss of me.  Had I written thi...          [Not Distorted]   \n",
       "4  This is literally all I think about. I frequen...          [Not Distorted]   \n",
       "\n",
       "   union_label_binary  Arbitrary Inference  Black and White Thinking  \\\n",
       "0                   0                    0                         0   \n",
       "1                   1                    0                         0   \n",
       "2                   0                    0                         0   \n",
       "3                   0                    0                         0   \n",
       "4                   0                    0                         0   \n",
       "\n",
       "   Catastrophizing  Labeling  Overgeneralization  Personalization  \\\n",
       "0                0         0                   0                0   \n",
       "1                0         0                   0                0   \n",
       "2                0         0                   0                0   \n",
       "3                0         0                   0                0   \n",
       "4                0         0                   0                0   \n",
       "\n",
       "   Selective Abstraction  \n",
       "0                      0  \n",
       "1                      1  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZepCattj0U5g"
   },
   "source": [
    "## BINARY LOGISTIC REGRESSION WITH GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkngIvNLzNrR",
    "outputId": "37993b43-337a-4f04-9c3b-3bb0e80cb25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.9687922000885\n",
      "Best Score: 0.675900166929008\n",
      "Best Hyperparameters: {'logreg__C': 10, 'vect__max_features': 5000, 'vect__min_df': 10}\n"
     ]
    }
   ],
   "source": [
    "#GRID SEARCH CV FOR PARAMETER TUNING \n",
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer()), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "parameters = {\n",
    "              'logreg__C': [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5,10,30,50],\n",
    "              'vect__max_features': [5000,4000,3000,2000,1000,500,5],\n",
    "              'vect__min_df': [1,3,5,10]\n",
    "              #'vect__min_df': [0.01, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "              }\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid=parameters, scoring='f1_weighted')\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(train['text'], train['union_label_binary'])\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print('Best Score: %s' % clf.best_score_)\n",
    "print('Best Hyperparameters: %s' % clf.best_params_)\n",
    "\n",
    "#print(\"\\n\")\n",
    "#preds = clf.best_estimator_.predict(validation['text'])\n",
    "#print(classification_report(validation['union_label_binary'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXNDKvWeCJzc",
    "outputId": "d9faa7ce-4fa6-4961-c090-e63415796b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09527397155761719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.40      0.43        15\n",
      "           1       0.76      0.80      0.78        35\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.61      0.60      0.60        50\n",
      "weighted avg       0.67      0.68      0.67        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PREDICTIONS ON TEST DATA\n",
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features = 5000, min_df = 10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1, C = 10))\n",
    "                  ])\n",
    "\n",
    "start = time.time()\n",
    "pipeline.fit(train['text'], train['union_label_binary'])\n",
    "preds = pipeline.predict(test['text'])\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print(classification_report(test['union_label_binary'],preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7ZpdOy_0ZaD"
   },
   "source": [
    "# MULTI-LABEL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtoR-F4c_ygC",
    "outputId": "563704ea-9117-48fe-9125-b6e283d54e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.89990472793579\n"
     ]
    }
   ],
   "source": [
    "#MANUAL HYPERPARAMETER TUNING ON VALIDATION SET (Grid search can also be used, but here we use the whole dataset available)\n",
    "\n",
    "results = []\n",
    "\n",
    "logreg__C = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5,10,30,50]\n",
    "vect_max_features = [5000,4000,3000,2000,1000,500,5]\n",
    "vect__min_df = [1,3,5,10]\n",
    "\n",
    "start = time.time()\n",
    "for C_ in logreg__C:\n",
    "  for max in vect_max_features:\n",
    "    for min in vect__min_df:\n",
    "\n",
    "      vectorizer = TfidfVectorizer(min_df=min, max_features = max) #strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2'\n",
    "      vectorizer.fit(train['text'])\n",
    "      X_train_transf = vectorizer.transform(train['text'])\n",
    "      X_val_transf = vectorizer.transform(validation['text'])\n",
    "\n",
    "      clf = MultiOutputClassifier(LogisticRegression(random_state=1, C=C_, solver='liblinear')).fit(X_train_transf, train.iloc[:, [3,4,5,6,7,8,9]])\n",
    "      predictions = clf.predict(X_val_transf)\n",
    "\n",
    "      F1_score = f1_score(validation.iloc[:, [3,4,5,6,7,8,9]], predictions, average = 'weighted')\n",
    "      results.append((F1_score, C_, max, min))\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1qHU9U-EUex",
    "outputId": "7e27c6d8-daf9-4cf3-d7c8-ab3ce1cd4fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.20243864793949687, 50, 500, 10)\n"
     ]
    }
   ],
   "source": [
    "#Find the best model and its hyperparameters according to the highest F1-score\n",
    "\n",
    "maxResult = False\n",
    "for result in results:\n",
    "  if (maxResult == False):\n",
    "    maxResult = result\n",
    "  else:\n",
    "    if result[0] >= maxResult[0]:\n",
    "      maxResult = result\n",
    "print(maxResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86ldWM7S_SVp",
    "outputId": "5e796f15-fe01-4f0c-c549-a0802a94fc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03837275505065918\n",
      "AUC score: 0.5068271046329558\n",
      "\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "     Arbitrary Inference       0.22      0.20      0.21        10\n",
      "Black and White Thinking       0.00      0.00      0.00         3\n",
      "         Catastrophizing       0.30      0.17      0.21        18\n",
      "                Labeling       0.50      0.17      0.25         6\n",
      "      Overgeneralization       0.00      0.00      0.00         4\n",
      "         Personalization       0.00      0.00      0.00         3\n",
      "   Selective Abstraction       0.00      0.00      0.00         6\n",
      "\n",
      "               micro avg       0.27      0.12      0.17        50\n",
      "               macro avg       0.15      0.08      0.10        50\n",
      "            weighted avg       0.21      0.12      0.15        50\n",
      "             samples avg       0.10      0.09      0.09        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#PREDICTIONS ON TEST DATA WITH THE BEST PARAMETERS\n",
    "vectorizer = TfidfVectorizer(min_df=10, max_features = 500) #strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2'\n",
    "vectorizer.fit(train['text'])\n",
    "\n",
    "X_train_transf = vectorizer.transform(train['text'])\n",
    "X_test_transf = vectorizer.transform(test['text'])\n",
    "\n",
    "start = time.time()\n",
    "clf = MultiOutputClassifier(LogisticRegression(random_state=1, C=50, solver='liblinear')).fit(X_train_transf, train.iloc[:, [3,4,5,6,7,8,9]])\n",
    "predictions = clf.predict(X_test_transf)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print('AUC score: {}'.format(roc_auc_score(test.iloc[:, [3,4,5,6,7,8,9]],predictions)))\n",
    "print('\\n')\n",
    "\n",
    "label_names = ['Arbitrary Inference',\t'Black and White Thinking',\t'Catastrophizing',\t'Labeling',\t'Overgeneralization',\t'Personalization',\t'Selective Abstraction']\n",
    "\n",
    "print(classification_report(test.iloc[:, [3,4,5,6,7,8,9]], predictions, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEKK1n6L14p3"
   },
   "source": [
    "# WITH PRE-PROCESSING BINARY LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bECPddZZ16p2"
   },
   "outputs": [],
   "source": [
    "#Pre-processing Source: https://machinelearningknowledge.ai/11-techniques-of-text-preprocessing-using-nltk-in-python/\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#PREPROCESSING TRAINING SET\n",
    "pre_train = copy.deepcopy(train)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_train['text'] = pre_train['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces \n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_train['text'] = pre_train['text'].apply(remove_whitespace)\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#Lemmatize\n",
    "pre_train['text'] = pre_train.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_train['text'] = pre_train['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHrmtA_u4_3D"
   },
   "outputs": [],
   "source": [
    "#PREPROCESSING VALIDATION SET\n",
    "pre_validation = copy.deepcopy(validation)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_validation['text'] = pre_validation['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces \n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_validation['text'] = pre_validation['text'].apply(remove_whitespace)\n",
    "\n",
    "#Lemmatize\n",
    "pre_validation['text'] = pre_validation.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_validation['text'] = pre_validation['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZGCsSIVM872"
   },
   "outputs": [],
   "source": [
    "#PREPROCESSING TEST SET\n",
    "pre_test = copy.deepcopy(test)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_test['text'] = pre_test['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces \n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_test['text'] = pre_test['text'].apply(remove_whitespace)\n",
    "\n",
    "#Lemmatize\n",
    "pre_test['text'] = pre_test.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_test['text'] = pre_test['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ayx0gmO4e4y",
    "outputId": "91cd7141-df98-4fea-fb89-74db70e0b540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.17226982116699\n",
      "Best Score: 0.6759083500550662\n",
      "Best Hyperparameters: {'logreg__C': 30, 'vect__max_features': 5000, 'vect__min_df': 10}\n"
     ]
    }
   ],
   "source": [
    "#GRID SEARCH CV FOR PARAMETER TUNING \n",
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer()), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "parameters = {\n",
    "              'logreg__C': [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5,10,30,50],\n",
    "              'vect__max_features': [5000,4000,3000,2000,1000,500,5],\n",
    "              'vect__min_df': [1,3,5,10]\n",
    "              }\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid=parameters, scoring = 'f1_weighted')\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(pre_train['text'], pre_train['union_label_binary'])\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print('Best Score: %s' % clf.best_score_)\n",
    "print('Best Hyperparameters: %s' % clf.best_params_)\n",
    "#print(\"\\n\")\n",
    "#print(classification_report(pre_validation['union_label_binary'],clf.best_estimator_.predict(pre_validation['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U8eGOXhNtRt",
    "outputId": "7f3eccb3-5ca0-4955-dafc-d74b77381af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057353973388671875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48        15\n",
      "           1       0.78      0.80      0.79        35\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.64      0.63      0.64        50\n",
      "weighted avg       0.69      0.70      0.70        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PREDICTIONS ON TEST DATA\n",
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features = 5000, min_df = 10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1, C = 30))\n",
    "                  ])\n",
    "\n",
    "start = time.time()\n",
    "pipeline.fit(pre_train['text'], pre_train['union_label_binary'])\n",
    "preds = pipeline.predict(pre_test['text'])\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print(classification_report(pre_test['union_label_binary'],preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RactN8RQ6DeZ"
   },
   "source": [
    "# WITH PRE-PROCESSING MULTI-LABEL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xaot0whC6FzB",
    "outputId": "f87f709d-4c39-46f5-f213-8b5ff21aca1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.36245369911194\n"
     ]
    }
   ],
   "source": [
    "#MANUAL HYPERPARAMETER TUNING ON VALIDATION SET\n",
    "\n",
    "results = []\n",
    "\n",
    "logreg__C = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5,10,30,50]\n",
    "vect_max_features = [5000,4000,3000,2000,1000,500,5]\n",
    "vect__min_df = [1,3,5,10]\n",
    "\n",
    "start = time.time()\n",
    "for C_ in logreg__C:\n",
    "  for max in vect_max_features:\n",
    "    for min in vect__min_df:\n",
    "\n",
    "      vectorizer = TfidfVectorizer(min_df=min, max_features = max) #strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2'\n",
    "      vectorizer.fit(pre_train['text'])\n",
    "      X_train_transf = vectorizer.transform(pre_train['text'])\n",
    "      X_val_transf = vectorizer.transform(pre_validation['text'])\n",
    "\n",
    "      clf = MultiOutputClassifier(LogisticRegression(random_state=1, C=C_, solver='liblinear')).fit(X_train_transf, pre_train.iloc[:, [3,4,5,6,7,8,9]])\n",
    "      predictions = clf.predict(X_val_transf)\n",
    "\n",
    "      F1_score = f1_score(pre_validation.iloc[:, [3,4,5,6,7,8,9]], predictions, average = 'weighted')\n",
    "      results.append((F1_score, C_, max, min))\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQbNIYeXOiN_",
    "outputId": "165f09f4-ba5d-4e43-f87e-e07cc8dac2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2066737090660536, 50, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "#Find the best model and its hyperparameters according to the highest F1-score\n",
    "\n",
    "maxResult = False\n",
    "for result in results:\n",
    "  if (maxResult == False):\n",
    "    maxResult = result\n",
    "  else:\n",
    "    if result[0] >= maxResult[0]:\n",
    "      maxResult = result\n",
    "print(maxResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGHUisElOne-",
    "outputId": "3c6d8792-db73-4381-b99b-b28abb143688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06790876388549805\n",
      "AUC score: 0.5150295700162721\n",
      "\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "     Arbitrary Inference       0.25      0.20      0.22        10\n",
      "Black and White Thinking       0.00      0.00      0.00         3\n",
      "         Catastrophizing       0.42      0.28      0.33        18\n",
      "                Labeling       0.50      0.17      0.25         6\n",
      "      Overgeneralization       0.00      0.00      0.00         4\n",
      "         Personalization       0.00      0.00      0.00         3\n",
      "   Selective Abstraction       0.00      0.00      0.00         6\n",
      "\n",
      "               micro avg       0.33      0.16      0.22        50\n",
      "               macro avg       0.17      0.09      0.12        50\n",
      "            weighted avg       0.26      0.16      0.19        50\n",
      "             samples avg       0.16      0.12      0.13        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#PREDICTIONS ON TEST SET\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3, max_features = 500) #strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2'\n",
    "vectorizer.fit(pre_train['text'])\n",
    "\n",
    "X_train_transf = vectorizer.transform(pre_train['text'])\n",
    "X_test_transf = vectorizer.transform(pre_test['text'])\n",
    "\n",
    "start = time.time()\n",
    "clf = MultiOutputClassifier(LogisticRegression(random_state=1, C=50, solver='liblinear')).fit(X_train_transf, pre_train.iloc[:, [3,4,5,6,7,8,9]])\n",
    "predictions = clf.predict(X_test_transf)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print('AUC score: {}'.format(roc_auc_score(pre_test.iloc[:, [3,4,5,6,7,8,9]],predictions)))\n",
    "print('\\n')\n",
    "\n",
    "label_names = ['Arbitrary Inference',\t'Black and White Thinking',\t'Catastrophizing',\t'Labeling',\t'Overgeneralization',\t'Personalization',\t'Selective Abstraction']\n",
    "\n",
    "print(classification_report(pre_test.iloc[:, [3,4,5,6,7,8,9]], predictions, target_names=label_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic_regression",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
