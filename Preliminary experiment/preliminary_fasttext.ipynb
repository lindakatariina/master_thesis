{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wBd3eEkDDSM"
   },
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TN-ggnMRspan",
    "outputId": "59af53be-5b77-4dee-d132-93fd05bc2e46"
   },
   "outputs": [],
   "source": [
    "#!pip install fasttext\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "B4QTlnd8spiT"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train_dataset.json',  orient=\"records\", lines = True)\n",
    "validation = pd.read_json('validation_dataset.json',  orient=\"records\", lines = True)\n",
    "test = pd.read_json('test_dataset.json',  orient=\"records\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "rq10baksBZY5"
   },
   "outputs": [],
   "source": [
    "X_val = validation['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muq0ulnDC6yW"
   },
   "source": [
    "## Binary fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "C0yUHo-v-qHK"
   },
   "outputs": [],
   "source": [
    "#CONVERT TRAINING DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "import copy\n",
    "\n",
    "binary_train = copy.deepcopy(train)\n",
    "binary_train['union_label_binary'] = binary_train['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "binary_train = binary_train[['text', 'union_label_binary']]\n",
    "binary_train['file_format'] = binary_train['union_label_binary'] + ' ' + binary_train['text']\n",
    "binary_train_file = binary_train['file_format']\n",
    "binary_train_file.to_csv('binary_train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "\n",
    "#CONVERT VALIDATION DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "binary_validation = copy.deepcopy(validation)\n",
    "binary_validation['union_label_binary'] = binary_validation['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "binary_validation = binary_validation[['text', 'union_label_binary']]\n",
    "binary_validation['file_format'] = binary_validation['union_label_binary'] + ' ' + binary_validation['text']\n",
    "binary_validation_file = binary_validation['file_format']\n",
    "binary_validation_file.to_csv('binary_validation_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "\n",
    "#CONVERT VALIDATION DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "binary_test = copy.deepcopy(test)\n",
    "binary_test['union_label_binary'] = binary_test['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "binary_test = binary_test[['text', 'union_label_binary']]\n",
    "binary_test['file_format'] = binary_test['union_label_binary'] + ' ' + binary_test['text']\n",
    "binary_test_file = binary_test['file_format']\n",
    "binary_test_file.to_csv('binary_test_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.34230518341064\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#WITH 10-CYCLE FOR LOOP FOR GETTING AVG OF F1-SCORE (bc there's no oppotrunity to set random_seed)\n",
    "\n",
    "#hyperparameter tuning\n",
    "learning_rates = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "nr_epochs = [5, 10, 15, 20, 25, 50]\n",
    "\n",
    "results = []\n",
    "stds = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for learn in learning_rates:\n",
    "    for epoch_ in nr_epochs:\n",
    "        F_scores = []\n",
    "        for i in range (0,10):\n",
    "            fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt',  lr = learn, epoch = epoch_)\n",
    "            y_pred = binary_validation['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "            F1_score = f1_score(binary_validation['union_label_binary'], y_pred, average = 'weighted')\n",
    "            F_scores.append(F1_score)\n",
    "        average = mean(F_scores)\n",
    "        std = stat.stdev(F_scores)\n",
    "        results.append((average, std, learn, epoch_))\n",
    "        stds.append((std, learn, epoch_))\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6446841971476563, 0.013623878613788894, 0.75, 10)\n"
     ]
    }
   ],
   "source": [
    "maxResult = False\n",
    "for result in results:\n",
    "    if (maxResult == False):\n",
    "        maxResult = result\n",
    "    else:\n",
    "        if result[0] >= maxResult[0]:\n",
    "            maxResult = result\n",
    "print(maxResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"for result in results:\\n    print(result)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"for result in results:\n",
    "    print(result)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max weighted F1_score is 0.6092105263157895\n",
      "Mean weighted F1_score is 0.6092105263157895\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING AND PREDICTION WITH BEST PARAMETERS ON TEST SET USING 10X RUN AVERAGE\n",
    "F_scores = []\n",
    "\n",
    "for i in range (0,10):\n",
    "    fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt',  lr = 0.75, epoch = 10)\n",
    "    y_pred = binary_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "    F_scores.append(f1_score(binary_test['union_label_binary'], y_pred, average = 'weighted'))\n",
    "    \n",
    "print('Max weighted F1_score is ' + str(max(F_scores)))\n",
    "print('Mean weighted F1_score is ' + str(mean(F_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.71      0.83      0.76        35\n",
      "__label__Not_Distorted       0.33      0.20      0.25        15\n",
      "\n",
      "              accuracy                           0.64        50\n",
      "             macro avg       0.52      0.51      0.51        50\n",
      "          weighted avg       0.60      0.64      0.61        50\n",
      "\n",
      "[[29  6]\n",
      " [12  3]]\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING AND PREDICTION WITH BEST PARAMETERS ON TEST SET (CAN CHANGE EVERYTIME YOU RUN)\n",
    "fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt',  lr = 0.75, epoch = 10)\n",
    "y_pred = binary_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "print(classification_report(binary_test['union_label_binary'], y_pred))\n",
    "print(confusion_matrix(binary_test['union_label_binary'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oambTNlZ84mr"
   },
   "source": [
    "## With pre-processing Binary Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ligren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://machinelearningknowledge.ai/11-techniques-of-text-preprocessing-using-nltk-in-python/\n",
    "#PREPROCESSING TRAINING SET\n",
    "pre_train = copy.deepcopy(train)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_train['text'] = pre_train['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_train['text'] = pre_train['text'].apply(remove_whitespace)\n",
    "\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#Lemmatize\n",
    "pre_train['text'] = pre_train.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_train['text'] = pre_train['text'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "\n",
    "#PREPROCESSING VALIDATION SET\n",
    "pre_validation = copy.deepcopy(validation)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_validation['text'] = pre_validation['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces \n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_validation['text'] = pre_validation['text'].apply(remove_whitespace)\n",
    "\n",
    "#Lemmatize\n",
    "pre_validation['text'] = pre_validation.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_validation['text'] = pre_validation['text'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PREPROCESSING TEST SET\n",
    "pre_test = copy.deepcopy(test)\n",
    "\n",
    "#Lowercasing text\n",
    "pre_test['text'] = pre_test['text'].str.lower()\n",
    "\n",
    "#Removing extra whitespaces\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "pre_test['text'] = pre_test['text'].apply(remove_whitespace)\n",
    "\n",
    "#Lemmatize\n",
    "pre_test['text'] = pre_test.text.apply(lemmatize_text)\n",
    "\n",
    "#join by whitespace\n",
    "pre_test['text'] = pre_test['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QaOAvsTB88Iv"
   },
   "outputs": [],
   "source": [
    "#CONVERT TRAINING DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "pre_train['union_label_binary'] = pre_train['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "pre_train = pre_train[['text', 'union_label_binary']]\n",
    "pre_train['file_format'] = pre_train['union_label_binary'] + ' ' + pre_train['text']\n",
    "pre_train_file = pre_train['file_format']\n",
    "pre_train_file.to_csv('PRE_binary_train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "\n",
    "\n",
    "\n",
    "#CONVERT VALIDATION DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "pre_validation['union_label_binary'] = pre_validation['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "pre_validation = pre_validation[['text', 'union_label_binary']]\n",
    "pre_validation['file_format'] = pre_validation['union_label_binary'] + ' ' + pre_validation['text']\n",
    "pre_validation_file = pre_validation['file_format']\n",
    "pre_validation_file.to_csv('PRE_binary_validation_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "\n",
    "\n",
    "\n",
    "#CONVERT TEST DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "pre_test['union_label_binary'] = pre_test['union_label_binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "pre_test = pre_test[['text', 'union_label_binary']]\n",
    "pre_test['file_format'] = pre_test['union_label_binary'] + ' ' + pre_test['text']\n",
    "pre_test_file = pre_test['file_format']\n",
    "pre_test_file.to_csv('PRE_binary_test_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.45967102050781\n"
     ]
    }
   ],
   "source": [
    "#WITH 10-CYCLE FOR LOOP FOR GETTING AVG OF F1-SCORE (bc there's no oppotrunity to set random_seed)\n",
    "\n",
    "#hyperparameter tuning\n",
    "learning_rates = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "nr_epochs = [5, 10, 15, 20, 25, 50]\n",
    "\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for learn in learning_rates:\n",
    "    for epoch_ in nr_epochs:\n",
    "        F_scores = []\n",
    "        for i in range (0,10):\n",
    "            fasttext_model = fasttext.train_supervised(input = 'PRE_binary_train_fasttext.txt',  lr = learn, epoch = epoch_)\n",
    "            y_pred = pre_validation['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "            F1_score = f1_score(pre_validation['union_label_binary'], y_pred, average = 'weighted')\n",
    "            F_scores.append(F1_score)\n",
    "        average = mean(F_scores)\n",
    "        results.append((average, learn, epoch_))\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6447640915312902, 0.5, 15)\n"
     ]
    }
   ],
   "source": [
    "maxResult = False\n",
    "for result in results:\n",
    "  if (maxResult == False):\n",
    "    maxResult = result\n",
    "  else:\n",
    "    if result[0] >= maxResult[0]:\n",
    "      maxResult = result\n",
    "print(maxResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max weighted F1_score is 0.6373333333333333\n",
      "Mean weighted F1_score is 0.6085100156404504\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING AND PREDICTION WITH BEST PARAMETERS ON TEST SET USING 10X RUN AVERAGE\n",
    "F_scores = []\n",
    "\n",
    "for i in range (0,10):\n",
    "    fasttext_model = fasttext.train_supervised(input = 'PRE_binary_train_fasttext.txt',  lr = 0.5, epoch = 15)\n",
    "    y_pred = pre_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "    F_scores.append(f1_score(pre_test['union_label_binary'], y_pred, average = 'weighted'))\n",
    "    \n",
    "print('Max weighted F1_score is ' + str(max(F_scores)))\n",
    "print('Mean weighted F1_score is ' + str(mean(F_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rr9x3tCaCeX1",
    "outputId": "3deb2a53-f58b-46dd-cebd-52a0e0b7ce83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.71      0.86      0.78        35\n",
      "__label__Not_Distorted       0.38      0.20      0.26        15\n",
      "\n",
      "              accuracy                           0.66        50\n",
      "             macro avg       0.54      0.53      0.52        50\n",
      "          weighted avg       0.61      0.66      0.62        50\n",
      "\n",
      "[[30  5]\n",
      " [12  3]]\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING AND PREDICTION WITH BEST PARAMETERS ON TEST SET (CAN CHANGE EVERYTIME YOU RUN)\n",
    "fasttext_model = fasttext.train_supervised(input = 'PRE_binary_train_fasttext.txt',  lr = 0.5, epoch = 15)\n",
    "y_pred = pre_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "print(classification_report(pre_test['union_label_binary'], y_pred))\n",
    "print(confusion_matrix(pre_test['union_label_binary'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbSXmQKUGLtN"
   },
   "source": [
    "## WITH PRETRAINED WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yCwSMHOqR9gs"
   },
   "outputs": [],
   "source": [
    "#!unzip wiki-news-300d-1M-subword.vec.zip -d wiki-news-300d-1M-subword.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3Ix_ijqPpSg"
   },
   "source": [
    "### Binary pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072.471356868744\n",
      "(0.5879416823214292, 0.25, 10)\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning \n",
    "#takes approx 17 minutes\n",
    "#If I would use 10x for loop for getting 10x avg per each parameter combination, the training will take 3hours.\n",
    "#So, 10x for loop will not be used here for the sake of time\n",
    "learning_rates = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "nr_epochs = [5, 10, 15, 20, 25, 50]\n",
    "#min_lengths = [1,2,3]\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for learn in learning_rates:\n",
    "    for epoch_ in nr_epochs:\n",
    "            fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt', lr = learn, epoch = epoch_, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "            y_pred = binary_validation['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "            F1_score = f1_score(binary_validation['union_label_binary'], y_pred, average = 'weighted')\n",
    "            F_scores.append(F1_score)\n",
    "            average = mean(F_scores)\n",
    "            results.append((average, learn, epoch_))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "maxResult = False\n",
    "for result in results:\n",
    "  if (maxResult == False):\n",
    "    maxResult = result\n",
    "  else:\n",
    "    if result[0] >= maxResult[0]:\n",
    "      maxResult = result\n",
    "print(maxResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335.96571040153503\n",
      "Max weighted F1_score is 0.5800415800415799\n",
      "Mean weighted F1_score is 0.5800415800415799\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING AND PREDICTION WITH BEST PARAMETERS ON TEST SET USING 10X RUN AVERAGE\n",
    "#It takes around\n",
    "\n",
    "F_scores = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range (0,10):\n",
    "    fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt',  lr = 0.25, epoch = 10, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "    y_pred = binary_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "    F_scores.append(f1_score(binary_test['union_label_binary'], y_pred, average = 'weighted'))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "print('Max weighted F1_score is ' + str(max(F_scores)))\n",
    "print('Mean weighted F1_score is ' + str(mean(F_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.69      0.77      0.73        35\n",
      "__label__Not_Distorted       0.27      0.20      0.23        15\n",
      "\n",
      "              accuracy                           0.60        50\n",
      "             macro avg       0.48      0.49      0.48        50\n",
      "          weighted avg       0.57      0.60      0.58        50\n",
      "\n",
      "[[27  8]\n",
      " [12  3]]\n"
     ]
    }
   ],
   "source": [
    "#with best parameters evaluation (may change with each run)\n",
    "fasttext_model = fasttext.train_supervised(input = 'binary_train_fasttext.txt',  lr = 0.25, epoch = 10, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "y_pred = binary_test['text'].apply(lambda x: fasttext_model.predict(x)[0][0])\n",
    "print(classification_report(binary_test['union_label_binary'], y_pred))\n",
    "print(confusion_matrix(binary_test['union_label_binary'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-label classification was also tried but did not work as expected, so this is not included in this file.\n",
    "#File can be provided to reviewer of thesis by request."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
