{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO-9rM5M5SnG"
   },
   "source": [
    "## LOADING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "srIR8fjSyLsM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BQm24Wq9yvnx"
   },
   "outputs": [],
   "source": [
    "intersection_df = pd.read_json('intersection_df.json',  orient=\"records\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AGauGIMSQmpK",
    "outputId": "506f8dc5-ed9d-4fc4-ba20-8df8844cbca9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3010d35d-8e70-48fb-914c-a32ff850d00e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_new</th>\n",
       "      <th>binary</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>label_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>1</td>\n",
       "      <td>Distorted</td>\n",
       "      <td>Catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've started to realise my nausea is mostly ca...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every single day that I get my work done witho...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For a long long time I have found it difficult...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m sorry. I know it hurts. I know the pain of...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3010d35d-8e70-48fb-914c-a32ff850d00e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3010d35d-8e70-48fb-914c-a32ff850d00e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3010d35d-8e70-48fb-914c-a32ff850d00e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text            label  \\\n",
       "0  I'm sure most people probably figured this is ...  Catastrophizing   \n",
       "1  I've started to realise my nausea is mostly ca...    Not Distorted   \n",
       "2  Every single day that I get my work done witho...    Not Distorted   \n",
       "3  For a long long time I have found it difficult...    Not Distorted   \n",
       "4  I’m sorry. I know it hurts. I know the pain of...    Not Distorted   \n",
       "\n",
       "         label_new  binary   label_binary      label_new_2  \n",
       "0  Catastrophizing       1      Distorted  Catastrophizing  \n",
       "1    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "2    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "3    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "4    Not Distorted       0  Not Distorted    Not Distorted  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di2R-3XtRCkg"
   },
   "source": [
    "## BINARY LOGISTIC REGRESSION WITH NESTED STRATIFIED KFOLD CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OJAsXhfxRU20"
   },
   "outputs": [],
   "source": [
    "# create dataset\n",
    "X = intersection_df['text']\n",
    "y = intersection_df['binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwDaDnaKRFjS",
    "outputId": "001e67a9-07ab-4d3f-ceeb-a33cd2ccad27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.809, est=0.654, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        15\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.82        22\n",
      "   macro avg       0.81      0.75      0.77        22\n",
      "weighted avg       0.82      0.82      0.81        22\n",
      "\n",
      ">f1score=0.752, est=0.693, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        15\n",
      "           1       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.76      0.68      0.70        22\n",
      "weighted avg       0.77      0.77      0.75        22\n",
      "\n",
      ">f1score=0.616, est=0.660, cfg={'logreg__C': 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80        15\n",
      "           1       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.60      0.54      0.51        22\n",
      "weighted avg       0.64      0.68      0.62        22\n",
      "\n",
      ">f1score=0.506, est=0.650, cfg={'logreg__C': 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.74        15\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.33      0.43      0.37        22\n",
      "weighted avg       0.44      0.59      0.51        22\n",
      "\n",
      ">f1score=0.612, est=0.659, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        16\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.36      0.50      0.42        22\n",
      "weighted avg       0.53      0.73      0.61        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.590, est=0.690, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81        16\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.36      0.47      0.41        22\n",
      "weighted avg       0.52      0.68      0.59        22\n",
      "\n",
      ">f1score=0.733, est=0.649, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        15\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.72      0.63      0.65        21\n",
      "weighted avg       0.75      0.76      0.73        21\n",
      "\n",
      ">f1score=0.733, est=0.685, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        15\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.72      0.63      0.65        21\n",
      "weighted avg       0.75      0.76      0.73        21\n",
      "\n",
      ">f1score=0.571, est=0.611, cfg={'logreg__C': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80        15\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.35      0.47      0.40        21\n",
      "weighted avg       0.50      0.67      0.57        21\n",
      "\n",
      ">f1score=0.694, est=0.642, cfg={'logreg__C': 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.88      0.58      0.57        21\n",
      "weighted avg       0.82      0.76      0.69        21\n",
      "\n",
      "\n",
      "\n",
      "F1-score weighted Mean and Std: 0.662 (0.091)\n",
      "Max F1-score weighted: 0.8087121212121211\n"
     ]
    }
   ],
   "source": [
    "#source: https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/?fbclid=IwAR0H80UxAb7r6cVgD2c5kAfqthfYBWOupzLwRk1Mg7l8BDcR9_EcASHHCsc\n",
    "#source: https://www.geeksforgeeks.org/stratified-k-fold-cross-validation/\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features=5000,min_df=10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X,y):\n",
    "  # split data\n",
    "  X_train, X_test = X[train_ix], X[test_ix]\n",
    "  y_train, y_test = y[train_ix], y[test_ix]\n",
    "  # configure the cross-validation procedure\n",
    "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "  # define the model\n",
    "  model = pipeline\n",
    "  # define search space\n",
    "  space = dict()\n",
    "  space['logreg__C'] = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5]\n",
    "  #space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
    "  #space['vect__min_df'] = [1,3,5,10]\n",
    "  # define search\n",
    "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
    "  # execute search\n",
    "  result = search.fit(X_train, y_train)\n",
    "  # get the best performing model fit on the whole training set\n",
    "  best_model = result.best_estimator_\n",
    "  # evaluate model on the hold out dataset\n",
    "  yhat = best_model.predict(X_test)\n",
    "  # evaluate the model\n",
    "  f1 = f1_score(y_test, yhat, average='weighted')\n",
    "  # store the result\n",
    "  outer_results.append(f1)\n",
    "  # report progress\n",
    "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
    "  print(classification_report(y_test, yhat))\n",
    "# summarize the estimated performance of the model\n",
    "print('\\n')\n",
    "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "print('Max F1-score weighted: ' + str(max(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RactN8RQ6DeZ"
   },
   "source": [
    "# MULTI-CLASS LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90A1v0pv0nsR"
   },
   "source": [
    "### Catastrophizing vs Other distortion vs Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoXhAgJKGHD3",
    "outputId": "4c3c504b-03da-46d3-a4c4-f154e9c36a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Distorted       152\n",
       "Catastrophizing      43\n",
       "Other distortion     12\n",
       "Labeling              9\n",
       "Name: label_new, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df['label_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9db5ZUDGywc",
    "outputId": "f5066720-920f-4cb0-f89c-41bf3e818939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catastrophizing     43\n",
       "Other distortion    12\n",
       "Labeling             9\n",
       "Name: label_new, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_distortions = intersection_df[intersection_df['binary'] == 1]\n",
    "df_with_distortions = df_with_distortions.reset_index(drop=True)\n",
    "df_with_distortions['label_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fjdCt-4XGP7Y"
   },
   "outputs": [],
   "source": [
    "X_multi = df_with_distortions['text']\n",
    "y_multi = df_with_distortions['label_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_jHgKA8Fq3l",
    "outputId": "060f9db7-d432-4fad-cdba-ccbf8cbca255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.687, est=0.585, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       1.00      0.50      0.67         2\n",
      "\n",
      "        accuracy                           0.75         8\n",
      "       macro avg       0.57      0.50      0.50         8\n",
      "    weighted avg       0.70      0.75      0.69         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.534, cfg={'logreg__C': 0.01}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.540, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.568, cfg={'logreg__C': 3}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.600, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.568, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.566, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.24      0.33      0.28         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.416, est=0.582, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.57      1.00      0.73         4\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.57         7\n",
      "       macro avg       0.19      0.33      0.24         7\n",
      "    weighted avg       0.33      0.57      0.42         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.416, est=0.590, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.57      1.00      0.73         4\n",
      "        Labeling       0.00      0.00      0.00         1\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.57         7\n",
      "       macro avg       0.19      0.33      0.24         7\n",
      "    weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "\n",
      "\n",
      "F1-score weighted Mean and Std: 0.566 (0.085)\n",
      "Max F1-score weighted: 0.6874999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features=5000,min_df=10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = StratifiedKFold(n_splits=9, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
    "  # split data\n",
    "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "  # configure the cross-validation procedure\n",
    "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "  # define the model\n",
    "  model = pipeline\n",
    "  # define search space\n",
    "  space = dict()\n",
    "  space['logreg__C'] = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5]\n",
    "  #space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
    "  #space['vect__min_df'] = [1,3,5,10]\n",
    "  # define search\n",
    "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
    "  # execute search\n",
    "  result = search.fit(X_train, y_train)\n",
    "  # get the best performing model fit on the whole training set\n",
    "  best_model = result.best_estimator_\n",
    "  # evaluate model on the hold out dataset\n",
    "  yhat = best_model.predict(X_test)\n",
    "  # evaluate the model\n",
    "  f1 = f1_score(y_test, yhat, average='weighted')\n",
    "  # store the result\n",
    "  outer_results.append(f1)\n",
    "  # report progress\n",
    "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
    "  print(classification_report(y_test, yhat))\n",
    "# summarize the estimated performance of the model\n",
    "print('\\n')\n",
    "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "print('Max F1-score weighted: ' + str(max(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiiMVSeN0vm_"
   },
   "source": [
    "### Catastrophizing vs Other vs Not distorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MP8rl4us0une",
    "outputId": "e7e418b0-2d8e-4f58-ce94-de04b44ccb19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Distorted       152\n",
       "Catastrophizing      43\n",
       "Other distortion     21\n",
       "Name: label_new_2, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df['label_new_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "z925eaC005ac"
   },
   "outputs": [],
   "source": [
    "X_multi = intersection_df['text']\n",
    "y_multi = intersection_df['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwI-QrQ51E_L",
    "outputId": "4824cf5d-2787-4232-a028-788b835b9629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.553, est=0.595, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         5\n",
      "   Not Distorted       0.68      1.00      0.81        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.68        22\n",
      "       macro avg       0.23      0.33      0.27        22\n",
      "    weighted avg       0.46      0.68      0.55        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.553, est=0.628, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         5\n",
      "   Not Distorted       0.68      1.00      0.81        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.68        22\n",
      "       macro avg       0.23      0.33      0.27        22\n",
      "    weighted avg       0.46      0.68      0.55        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.568, est=0.612, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         5\n",
      "   Not Distorted       0.71      1.00      0.83        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.68        22\n",
      "       macro avg       0.24      0.33      0.28        22\n",
      "    weighted avg       0.49      0.68      0.57        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.768, est=0.589, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       1.00      0.50      0.67         4\n",
      "   Not Distorted       0.80      1.00      0.89        16\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.82        22\n",
      "       macro avg       0.60      0.50      0.52        22\n",
      "    weighted avg       0.76      0.82      0.77        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.612, est=0.610, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.73      1.00      0.84        16\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.73        22\n",
      "       macro avg       0.24      0.33      0.28        22\n",
      "    weighted avg       0.53      0.73      0.61        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.553, est=0.585, cfg={'logreg__C': 0.01}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.68      1.00      0.81        15\n",
      "Other distortion       0.00      0.00      0.00         3\n",
      "\n",
      "        accuracy                           0.68        22\n",
      "       macro avg       0.23      0.33      0.27        22\n",
      "    weighted avg       0.46      0.68      0.55        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.571, est=0.592, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.70      0.93      0.80        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.67        21\n",
      "       macro avg       0.23      0.31      0.27        21\n",
      "    weighted avg       0.50      0.67      0.57        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.612, est=0.593, cfg={'logreg__C': 3}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.75      1.00      0.86        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.71        21\n",
      "       macro avg       0.25      0.33      0.29        21\n",
      "    weighted avg       0.54      0.71      0.61        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.546, est=0.600, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.68      0.87      0.76        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.62        21\n",
      "       macro avg       0.23      0.29      0.25        21\n",
      "    weighted avg       0.49      0.62      0.55        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.595, est=0.609, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.00      0.00      0.00         4\n",
      "   Not Distorted       0.71      1.00      0.83        15\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.71        21\n",
      "       macro avg       0.24      0.33      0.28        21\n",
      "    weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "\n",
      "\n",
      "F1-score weighted Mean and Std: 0.593 (0.063)\n",
      "Max F1-score weighted: 0.7676767676767677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features=5000,min_df=10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
    "  # split data\n",
    "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "  # configure the cross-validation procedure\n",
    "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "  # define the model\n",
    "  model = pipeline\n",
    "  # define search space\n",
    "  space = dict()\n",
    "  space['logreg__C'] = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5]\n",
    "  #space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
    "  #space['vect__min_df'] = [1,3,5,10]\n",
    "  # define search\n",
    "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
    "  # execute search\n",
    "  result = search.fit(X_train, y_train)\n",
    "  # get the best performing model fit on the whole training set\n",
    "  best_model = result.best_estimator_\n",
    "  # evaluate model on the hold out dataset\n",
    "  yhat = best_model.predict(X_test)\n",
    "  # evaluate the model\n",
    "  f1 = f1_score(y_test, yhat, average='weighted')\n",
    "  # store the result\n",
    "  outer_results.append(f1)\n",
    "  # report progress\n",
    "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
    "  print(classification_report(y_test, yhat))\n",
    "# summarize the estimated performance of the model\n",
    "print('\\n')\n",
    "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "print('Max F1-score weighted: ' + str(max(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsZClxL21w2C"
   },
   "source": [
    "# BINARY - catastrophizing vs other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YP7vhEbi100B"
   },
   "outputs": [],
   "source": [
    "X_multi = df_with_distortions['text']\n",
    "y_multi = df_with_distortions['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_oNx7qw2a1D",
    "outputId": "f3b21659-b308-44ac-b545-a49cb0af62e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catastrophizing     43\n",
       "Other distortion    21\n",
       "Name: label_new_2, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhMPlG3a2dE5",
    "outputId": "68735d12-53a7-432f-b90b-952ac7514662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.429, est=0.589, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.60      0.60      0.60         5\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.43         7\n",
      "       macro avg       0.30      0.30      0.30         7\n",
      "    weighted avg       0.43      0.43      0.43         7\n",
      "\n",
      ">f1score=0.595, est=0.594, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.71      1.00      0.83         5\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.71         7\n",
      "       macro avg       0.36      0.50      0.42         7\n",
      "    weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.840, est=0.563, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.83      1.00      0.91         5\n",
      "Other distortion       1.00      0.50      0.67         2\n",
      "\n",
      "        accuracy                           0.86         7\n",
      "       macro avg       0.92      0.75      0.79         7\n",
      "    weighted avg       0.88      0.86      0.84         7\n",
      "\n",
      ">f1score=0.416, est=0.628, cfg={'logreg__C': 3}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.57      1.00      0.73         4\n",
      "Other distortion       0.00      0.00      0.00         3\n",
      "\n",
      "        accuracy                           0.57         7\n",
      "       macro avg       0.29      0.50      0.36         7\n",
      "    weighted avg       0.33      0.57      0.42         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.815, est=0.564, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.80      1.00      0.89         4\n",
      "Other distortion       1.00      0.50      0.67         2\n",
      "\n",
      "        accuracy                           0.83         6\n",
      "       macro avg       0.90      0.75      0.78         6\n",
      "    weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      ">f1score=0.533, est=0.588, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.67      1.00      0.80         4\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.67         6\n",
      "       macro avg       0.33      0.50      0.40         6\n",
      "    weighted avg       0.44      0.67      0.53         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.444, est=0.656, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.60      0.75      0.67         4\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.50         6\n",
      "       macro avg       0.30      0.38      0.33         6\n",
      "    weighted avg       0.40      0.50      0.44         6\n",
      "\n",
      ">f1score=0.533, est=0.594, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.67      1.00      0.80         4\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.67         6\n",
      "       macro avg       0.33      0.50      0.40         6\n",
      "    weighted avg       0.44      0.67      0.53         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.533, est=0.569, cfg={'logreg__C': 3}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.67      1.00      0.80         4\n",
      "Other distortion       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.67         6\n",
      "       macro avg       0.33      0.50      0.40         6\n",
      "    weighted avg       0.44      0.67      0.53         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">f1score=0.667, est=0.600, cfg={'logreg__C': 5}\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Catastrophizing       0.75      0.75      0.75         4\n",
      "Other distortion       0.50      0.50      0.50         2\n",
      "\n",
      "        accuracy                           0.67         6\n",
      "       macro avg       0.62      0.62      0.62         6\n",
      "    weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "\n",
      "\n",
      "F1-score weighted Mean and Std: 0.581 (0.143)\n",
      "Max F1-score weighted: 0.8398268398268397\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                  ('vect', CountVectorizer(max_features=5000,min_df=10)), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('logreg', LogisticRegression(solver='liblinear', random_state=1))\n",
    "                  ])\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
    "  # split data\n",
    "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "  # configure the cross-validation procedure\n",
    "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "  # define the model\n",
    "  model = pipeline\n",
    "  # define search space\n",
    "  space = dict()\n",
    "  space['logreg__C'] = [0.01,0.03,0.05,0.1,0.3,0.5,1,3,5]\n",
    "  #space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
    "  #space['vect__min_df'] = [1,3,5,10]\n",
    "  # define search\n",
    "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
    "  # execute search\n",
    "  result = search.fit(X_train, y_train)\n",
    "  # get the best performing model fit on the whole training set\n",
    "  best_model = result.best_estimator_\n",
    "  # evaluate model on the hold out dataset\n",
    "  yhat = best_model.predict(X_test)\n",
    "  # evaluate the model\n",
    "  f1 = f1_score(y_test, yhat, average='weighted')\n",
    "  # store the result\n",
    "  outer_results.append(f1)\n",
    "  # report progress\n",
    "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
    "  print(classification_report(y_test, yhat))\n",
    "# summarize the estimated performance of the model\n",
    "print('\\n')\n",
    "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "print('Max F1-score weighted: ' + str(max(outer_results)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Uus - Multiclass Logistic_regression",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
