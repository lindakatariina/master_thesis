{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wBd3eEkDDSM"
   },
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TN-ggnMRspan",
    "outputId": "59af53be-5b77-4dee-d132-93fd05bc2e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in c:\\users\\ligren\\anaconda3\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ligren\\anaconda3\\lib\\site-packages (from fasttext) (1.19.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\ligren\\anaconda3\\lib\\site-packages (from fasttext) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\ligren\\anaconda3\\lib\\site-packages (from fasttext) (2.9.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ligren\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B4QTlnd8spiT"
   },
   "outputs": [],
   "source": [
    "intersection_df = pd.read_json('intersection_df.json',  orient=\"records\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_new</th>\n",
       "      <th>binary</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>label_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>1</td>\n",
       "      <td>Distorted</td>\n",
       "      <td>Catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've started to realise my nausea is mostly ca...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every single day that I get my work done witho...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For a long long time I have found it difficult...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m sorry. I know it hurts. I know the pain of...</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Distorted</td>\n",
       "      <td>Not Distorted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            label  \\\n",
       "0  I'm sure most people probably figured this is ...  Catastrophizing   \n",
       "1  I've started to realise my nausea is mostly ca...    Not Distorted   \n",
       "2  Every single day that I get my work done witho...    Not Distorted   \n",
       "3  For a long long time I have found it difficult...    Not Distorted   \n",
       "4  I’m sorry. I know it hurts. I know the pain of...    Not Distorted   \n",
       "\n",
       "         label_new  binary   label_binary      label_new_2  \n",
       "0  Catastrophizing       1      Distorted  Catastrophizing  \n",
       "1    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "2    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "3    Not Distorted       0  Not Distorted    Not Distorted  \n",
       "4    Not Distorted       0  Not Distorted    Not Distorted  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muq0ulnDC6yW"
   },
   "source": [
    "## Binary - Dist vs Not Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "C0yUHo-v-qHK"
   },
   "outputs": [],
   "source": [
    "#CONVERT DATA INTO SUITABLE FORMAT FOR FASTTEXT\n",
    "import copy\n",
    "\n",
    "fasttext_df = copy.deepcopy(intersection_df)\n",
    "fasttext_df['binary'] = fasttext_df['binary'].apply(lambda x: '__label__' + 'Not_Distorted' if x == 0 else '__label__' + 'Distorted')\n",
    "fasttext_df = fasttext_df[['text', 'binary']]\n",
    "fasttext_df['file_format'] = fasttext_df['binary'] + ' ' + fasttext_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "X = fasttext_df['text']\n",
    "y = fasttext_df['binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.62\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.40      0.29      0.33         7\n",
      "__label__Not_Distorted       0.71      0.80      0.75        15\n",
      "\n",
      "              accuracy                           0.64        22\n",
      "             macro avg       0.55      0.54      0.54        22\n",
      "          weighted avg       0.61      0.64      0.62        22\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.69\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.67      0.29      0.40         7\n",
      "__label__Not_Distorted       0.74      0.93      0.82        15\n",
      "\n",
      "              accuracy                           0.73        22\n",
      "             macro avg       0.70      0.61      0.61        22\n",
      "          weighted avg       0.71      0.73      0.69        22\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.59\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.33      0.14      0.20         7\n",
      "__label__Not_Distorted       0.68      0.87      0.76        15\n",
      "\n",
      "              accuracy                           0.64        22\n",
      "             macro avg       0.51      0.50      0.48        22\n",
      "          weighted avg       0.57      0.64      0.59        22\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.65\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       1.00      0.14      0.25         7\n",
      "__label__Not_Distorted       0.71      1.00      0.83        15\n",
      "\n",
      "              accuracy                           0.73        22\n",
      "             macro avg       0.86      0.57      0.54        22\n",
      "          weighted avg       0.81      0.73      0.65        22\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.59\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.00      0.00      0.00         6\n",
      "__label__Not_Distorted       0.71      0.94      0.81        16\n",
      "\n",
      "              accuracy                           0.68        22\n",
      "             macro avg       0.36      0.47      0.41        22\n",
      "          weighted avg       0.52      0.68      0.59        22\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.57\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.00      0.00      0.00         6\n",
      "__label__Not_Distorted       0.70      0.88      0.78        16\n",
      "\n",
      "              accuracy                           0.64        22\n",
      "             macro avg       0.35      0.44      0.39        22\n",
      "          weighted avg       0.51      0.64      0.57        22\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.63\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.33      0.17      0.22         6\n",
      "__label__Not_Distorted       0.72      0.87      0.79        15\n",
      "\n",
      "              accuracy                           0.67        21\n",
      "             macro avg       0.53      0.52      0.51        21\n",
      "          weighted avg       0.61      0.67      0.63        21\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.77\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       1.00      0.33      0.50         6\n",
      "__label__Not_Distorted       0.79      1.00      0.88        15\n",
      "\n",
      "              accuracy                           0.81        21\n",
      "             macro avg       0.89      0.67      0.69        21\n",
      "          weighted avg       0.85      0.81      0.77        21\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.00      0.00      0.00         6\n",
      "__label__Not_Distorted       0.71      1.00      0.83        15\n",
      "\n",
      "              accuracy                           0.71        21\n",
      "             macro avg       0.36      0.50      0.42        21\n",
      "          weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.69\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       1.00      0.17      0.29         6\n",
      "__label__Not_Distorted       0.75      1.00      0.86        15\n",
      "\n",
      "              accuracy                           0.76        21\n",
      "             macro avg       0.88      0.58      0.57        21\n",
      "          weighted avg       0.82      0.76      0.69        21\n",
      "\n",
      "Max F1_score across folds is 0.7731092436974789 and mean score is 0.6382772978151129\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X,y):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 0.25, epoch = 25)\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic8FEggjA7dm"
   },
   "source": [
    "## Binary - Catastrophizing vs Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LMvbscU2spm5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catastrophizing     43\n",
       "Other distortion    21\n",
       "Name: label_new_2, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_distortions = intersection_df[intersection_df['binary'] != 0]\n",
    "df_with_distortions = df_with_distortions.reset_index(drop=True)\n",
    "df_with_distortions['label_new_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I know therapy has its ups and downs, but I fe...</td>\n",
       "      <td>__label__other-distortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm currently having a panic attack because I'...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So I'll try to describe this the best I can.  ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been having this problem for a while.  Ju...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I'm sure most people probably figured this is ...   \n",
       "1  I know therapy has its ups and downs, but I fe...   \n",
       "2  I'm currently having a panic attack because I'...   \n",
       "3  So I'll try to describe this the best I can.  ...   \n",
       "4  I've been having this problem for a while.  Ju...   \n",
       "\n",
       "                 label_new_2  \n",
       "0   __label__catastrophizing  \n",
       "1  __label__other-distortion  \n",
       "2   __label__catastrophizing  \n",
       "3   __label__catastrophizing  \n",
       "4   __label__catastrophizing  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_other = copy.deepcopy(df_with_distortions)\n",
    "df_cat_other = df_cat_other[['text', 'label_new_2']]\n",
    "df_cat_other['label_new_2'] = df_cat_other['label_new_2'].apply(lambda x: '__label__' + x.replace(' ', '-').lower())\n",
    "df_cat_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat_other['text']\n",
    "y = df_cat_other['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.36      0.50      0.42         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.36      0.50      0.42         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.36      0.50      0.42         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.42\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      1.00      0.73         4\n",
      "__label__other-distortion       0.00      0.00      0.00         3\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.29      0.50      0.36         7\n",
      "             weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "Max F1_score across folds is 0.5952380952380951 and mean score is 0.5401298701298701\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X,y):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 0.25, epoch = 25)\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbSXmQKUGLtN"
   },
   "source": [
    "## Binary with pre-trained vectors - Dist vs Not Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yCwSMHOqR9gs"
   },
   "outputs": [],
   "source": [
    "#!unzip wiki-news-300d-1M-subword.vec.zip -d wiki-news-300d-1M-subword.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "X = fasttext_df['text']\n",
    "y = fasttext_df['binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.73\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.57      0.57      0.57         7\n",
      "__label__Not_Distorted       0.80      0.80      0.80        15\n",
      "\n",
      "              accuracy                           0.73        22\n",
      "             macro avg       0.69      0.69      0.69        22\n",
      "          weighted avg       0.73      0.73      0.73        22\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.78\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.62      0.71      0.67         7\n",
      "__label__Not_Distorted       0.86      0.80      0.83        15\n",
      "\n",
      "              accuracy                           0.77        22\n",
      "             macro avg       0.74      0.76      0.75        22\n",
      "          weighted avg       0.78      0.77      0.78        22\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.51\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.25      0.29      0.27         7\n",
      "__label__Not_Distorted       0.64      0.60      0.62        15\n",
      "\n",
      "              accuracy                           0.50        22\n",
      "             macro avg       0.45      0.44      0.44        22\n",
      "          weighted avg       0.52      0.50      0.51        22\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.78\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.62      0.71      0.67         7\n",
      "__label__Not_Distorted       0.86      0.80      0.83        15\n",
      "\n",
      "              accuracy                           0.77        22\n",
      "             macro avg       0.74      0.76      0.75        22\n",
      "          weighted avg       0.78      0.77      0.78        22\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.58\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.20      0.17      0.18         6\n",
      "__label__Not_Distorted       0.71      0.75      0.73        16\n",
      "\n",
      "              accuracy                           0.59        22\n",
      "             macro avg       0.45      0.46      0.45        22\n",
      "          weighted avg       0.57      0.59      0.58        22\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.51\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.14      0.17      0.15         6\n",
      "__label__Not_Distorted       0.67      0.62      0.65        16\n",
      "\n",
      "              accuracy                           0.50        22\n",
      "             macro avg       0.40      0.40      0.40        22\n",
      "          weighted avg       0.52      0.50      0.51        22\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.71\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.50      0.50      0.50         6\n",
      "__label__Not_Distorted       0.80      0.80      0.80        15\n",
      "\n",
      "              accuracy                           0.71        21\n",
      "             macro avg       0.65      0.65      0.65        21\n",
      "          weighted avg       0.71      0.71      0.71        21\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.85\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.80      0.67      0.73         6\n",
      "__label__Not_Distorted       0.88      0.93      0.90        15\n",
      "\n",
      "              accuracy                           0.86        21\n",
      "             macro avg       0.84      0.80      0.82        21\n",
      "          weighted avg       0.85      0.86      0.85        21\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.66\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.50      0.17      0.25         6\n",
      "__label__Not_Distorted       0.74      0.93      0.82        15\n",
      "\n",
      "              accuracy                           0.71        21\n",
      "             macro avg       0.62      0.55      0.54        21\n",
      "          weighted avg       0.67      0.71      0.66        21\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.69\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distorted       0.50      0.33      0.40         6\n",
      "__label__Not_Distorted       0.76      0.87      0.81        15\n",
      "\n",
      "              accuracy                           0.71        21\n",
      "             macro avg       0.63      0.60      0.61        21\n",
      "          weighted avg       0.69      0.71      0.69        21\n",
      "\n",
      "Max F1_score across folds is 0.8529534981147885 and mean score is 0.6799312359180201\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X,y):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 10, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary with pre-trained vectors - Catastrophizing vs Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat_other['text']\n",
    "y = df_cat_other['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.43\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.60      0.60      0.60         5\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.43         7\n",
      "                macro avg       0.30      0.30      0.30         7\n",
      "             weighted avg       0.43      0.43      0.43         7\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.36      0.50      0.42         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_2 is 0.71\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      0.80      0.80         5\n",
      "__label__other-distortion       0.50      0.50      0.50         2\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.65      0.65      0.65         7\n",
      "             weighted avg       0.71      0.71      0.71         7\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.42\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      1.00      0.73         4\n",
      "__label__other-distortion       0.00      0.00      0.00         3\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.29      0.50      0.36         7\n",
      "             weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.81\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      1.00      0.89         4\n",
      "__label__other-distortion       1.00      0.50      0.67         2\n",
      "\n",
      "                 accuracy                           0.83         6\n",
      "                macro avg       0.90      0.75      0.78         6\n",
      "             weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.67\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       1.00      0.50      0.67         4\n",
      "__label__other-distortion       0.50      1.00      0.67         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.75      0.75      0.67         6\n",
      "             weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.67\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.75      0.75      0.75         4\n",
      "__label__other-distortion       0.50      0.50      0.50         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.62      0.62      0.62         6\n",
      "             weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.81\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      1.00      0.89         4\n",
      "__label__other-distortion       1.00      0.50      0.67         2\n",
      "\n",
      "                 accuracy                           0.83         6\n",
      "                macro avg       0.90      0.75      0.78         6\n",
      "             weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.81\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      1.00      0.89         4\n",
      "__label__other-distortion       1.00      0.50      0.67         2\n",
      "\n",
      "                 accuracy                           0.83         6\n",
      "                macro avg       0.90      0.75      0.78         6\n",
      "             weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67         6\n",
      "                macro avg       0.33      0.50      0.40         6\n",
      "             weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "Max F1_score across folds is 0.8148148148148149 and mean score is 0.6464790764790765\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X,y):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 10, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class - Catastrophizing vs Other vs Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catastrophizing     43\n",
       "Other distortion    12\n",
       "Labeling             9\n",
       "Name: label_new, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_distortions['label_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I know therapy has its ups and downs, but I fe...</td>\n",
       "      <td>__label__labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm currently having a panic attack because I'...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So I'll try to describe this the best I can.  ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been having this problem for a while.  Ju...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 label_new\n",
       "0  I'm sure most people probably figured this is ...  __label__catastrophizing\n",
       "1  I know therapy has its ups and downs, but I fe...         __label__labeling\n",
       "2  I'm currently having a panic attack because I'...  __label__catastrophizing\n",
       "3  So I'll try to describe this the best I can.  ...  __label__catastrophizing\n",
       "4  I've been having this problem for a while.  Ju...  __label__catastrophizing"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_other = copy.deepcopy(df_with_distortions)\n",
    "df_cat_other = df_cat_other[['text', 'label_new']]\n",
    "df_cat_other['label_new'] = df_cat_other['label_new'].apply(lambda x: '__label__' + x.replace(' ', '-').lower())\n",
    "df_cat_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df_cat_other['text']\n",
    "y_multi = df_cat_other['label_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.48\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.62      1.00      0.77         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.62         8\n",
      "                macro avg       0.21      0.33      0.26         8\n",
      "             weighted avg       0.39      0.62      0.48         8\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.24      0.33      0.28         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.24      0.33      0.28         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.79\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.83      1.00      0.91         5\n",
      "        __label__labeling       1.00      1.00      1.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.86         7\n",
      "                macro avg       0.61      0.67      0.64         7\n",
      "             weighted avg       0.74      0.86      0.79         7\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.24      0.33      0.28         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.24      0.33      0.28         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.79\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.83      1.00      0.91         5\n",
      "        __label__labeling       1.00      1.00      1.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.86         7\n",
      "                macro avg       0.61      0.67      0.64         7\n",
      "             weighted avg       0.74      0.86      0.79         7\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.42\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      1.00      0.73         4\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.19      0.33      0.24         7\n",
      "             weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.42\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      1.00      0.73         4\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.19      0.33      0.24         7\n",
      "             weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "Max F1_score across folds is 0.7922077922077921 and mean score is 0.5863673363673363\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=9, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X_multi,y_multi):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "    y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 15)\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class - Catastrophizing vs Other vs Not Distorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Distorted       152\n",
       "Catastrophizing      43\n",
       "Other distortion     21\n",
       "Name: label_new_2, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df['label_new_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've started to realise my nausea is mostly ca...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every single day that I get my work done witho...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For a long long time I have found it difficult...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m sorry. I know it hurts. I know the pain of...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label_new_2\n",
       "0  I'm sure most people probably figured this is ...  __label__catastrophizing\n",
       "1  I've started to realise my nausea is mostly ca...    __label__not-distorted\n",
       "2  Every single day that I get my work done witho...    __label__not-distorted\n",
       "3  For a long long time I have found it difficult...    __label__not-distorted\n",
       "4  I’m sorry. I know it hurts. I know the pain of...    __label__not-distorted"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_other = copy.deepcopy(intersection_df)\n",
    "df_cat_other = df_cat_other[['text', 'label_new_2']]\n",
    "df_cat_other['label_new_2'] = df_cat_other['label_new_2'].apply(lambda x: '__label__' + x.replace(' ', '-').lower())\n",
    "df_cat_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df_cat_other['text']\n",
    "y_multi = df_cat_other['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.74\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      0.80      0.67         5\n",
      "   __label__not-distorted       0.87      0.87      0.87        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.77        22\n",
      "                macro avg       0.48      0.56      0.51        22\n",
      "             weighted avg       0.72      0.77      0.74        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_1 is 0.61\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.50      0.20      0.29         5\n",
      "   __label__not-distorted       0.70      0.93      0.80        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.68        22\n",
      "                macro avg       0.40      0.38      0.36        22\n",
      "             weighted avg       0.59      0.68      0.61        22\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.62\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.33      0.20      0.25         5\n",
      "   __label__not-distorted       0.74      0.93      0.82        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.68        22\n",
      "                macro avg       0.36      0.38      0.36        22\n",
      "             weighted avg       0.58      0.68      0.62        22\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.66\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.33      0.50      0.40         4\n",
      "   __label__not-distorted       0.81      0.81      0.81        16\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.68        22\n",
      "                macro avg       0.38      0.44      0.40        22\n",
      "             weighted avg       0.65      0.68      0.66        22\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.56\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.72      0.81      0.76        16\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.59        22\n",
      "                macro avg       0.24      0.27      0.25        22\n",
      "             weighted avg       0.53      0.59      0.56        22\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.57\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.71      1.00      0.83        15\n",
      "__label__other-distortion       0.00      0.00      0.00         3\n",
      "\n",
      "                 accuracy                           0.68        22\n",
      "                macro avg       0.24      0.33      0.28        22\n",
      "             weighted avg       0.49      0.68      0.57        22\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.63\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.25      0.25      0.25         4\n",
      "   __label__not-distorted       0.76      0.87      0.81        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67        21\n",
      "                macro avg       0.34      0.37      0.35        21\n",
      "             weighted avg       0.59      0.67      0.63        21\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.53\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.14      0.25      0.18         4\n",
      "   __label__not-distorted       0.71      0.67      0.69        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.52        21\n",
      "                macro avg       0.29      0.31      0.29        21\n",
      "             weighted avg       0.54      0.52      0.53        21\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.62\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.33      0.25      0.29         4\n",
      "   __label__not-distorted       0.72      0.87      0.79        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67        21\n",
      "                macro avg       0.35      0.37      0.36        21\n",
      "             weighted avg       0.58      0.67      0.62        21\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.55\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.75      0.80      0.77        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57        21\n",
      "                macro avg       0.25      0.27      0.26        21\n",
      "             weighted avg       0.54      0.57      0.55        21\n",
      "\n",
      "Max F1_score across folds is 0.7424242424242423 and mean score is 0.608450406100351\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X_multi,y_multi):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "    y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 15)\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class with pre-trained vectors - Catastrophizing vs Other vs Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catastrophizing     43\n",
       "Other distortion    12\n",
       "Labeling             9\n",
       "Name: label_new, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_distortions['label_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I know therapy has its ups and downs, but I fe...</td>\n",
       "      <td>__label__labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm currently having a panic attack because I'...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So I'll try to describe this the best I can.  ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been having this problem for a while.  Ju...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 label_new\n",
       "0  I'm sure most people probably figured this is ...  __label__catastrophizing\n",
       "1  I know therapy has its ups and downs, but I fe...         __label__labeling\n",
       "2  I'm currently having a panic attack because I'...  __label__catastrophizing\n",
       "3  So I'll try to describe this the best I can.  ...  __label__catastrophizing\n",
       "4  I've been having this problem for a while.  Ju...  __label__catastrophizing"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_other = copy.deepcopy(df_with_distortions)\n",
    "df_cat_other = df_cat_other[['text', 'label_new']]\n",
    "df_cat_other['label_new'] = df_cat_other['label_new'].apply(lambda x: '__label__' + x.replace(' ', '-').lower())\n",
    "df_cat_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df_cat_other['text']\n",
    "y_multi = df_cat_other['label_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.48\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.62      1.00      0.77         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.62         8\n",
      "                macro avg       0.21      0.33      0.26         8\n",
      "             weighted avg       0.39      0.62      0.48         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_1 is 0.65\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.83      1.00      0.91         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.28      0.33      0.30         7\n",
      "             weighted avg       0.60      0.71      0.65         7\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.65\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.83      1.00      0.91         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.28      0.33      0.30         7\n",
      "             weighted avg       0.60      0.71      0.65         7\n",
      "\n",
      "F1_score weighted of a fold nr_3 is 0.79\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.83      1.00      0.91         5\n",
      "        __label__labeling       1.00      1.00      1.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.86         7\n",
      "                macro avg       0.61      0.67      0.64         7\n",
      "             weighted avg       0.74      0.86      0.79         7\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.57\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      0.80      0.80         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.27      0.27      0.27         7\n",
      "             weighted avg       0.57      0.57      0.57         7\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.6\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.71      1.00      0.83         5\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.24      0.33      0.28         7\n",
      "             weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.71\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.80      0.80      0.80         5\n",
      "        __label__labeling       1.00      1.00      1.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         1\n",
      "\n",
      "                 accuracy                           0.71         7\n",
      "                macro avg       0.60      0.60      0.60         7\n",
      "             weighted avg       0.71      0.71      0.71         7\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.46\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.67      1.00      0.80         4\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.22      0.33      0.27         7\n",
      "             weighted avg       0.38      0.57      0.46         7\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.42\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.57      1.00      0.73         4\n",
      "        __label__labeling       0.00      0.00      0.00         1\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57         7\n",
      "                macro avg       0.19      0.33      0.24         7\n",
      "             weighted avg       0.33      0.57      0.42         7\n",
      "\n",
      "Max F1_score across folds is 0.7922077922077921 and mean score is 0.5917064417064417\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=9, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X_multi,y_multi):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "    y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 15, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class with pre-trained vectors - Catastrophizing vs Other vs Not Distorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Distorted       152\n",
       "Catastrophizing      43\n",
       "Other distortion     21\n",
       "Name: label_new_2, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df['label_new_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_new_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure most people probably figured this is ...</td>\n",
       "      <td>__label__catastrophizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've started to realise my nausea is mostly ca...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every single day that I get my work done witho...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For a long long time I have found it difficult...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m sorry. I know it hurts. I know the pain of...</td>\n",
       "      <td>__label__not-distorted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label_new_2\n",
       "0  I'm sure most people probably figured this is ...  __label__catastrophizing\n",
       "1  I've started to realise my nausea is mostly ca...    __label__not-distorted\n",
       "2  Every single day that I get my work done witho...    __label__not-distorted\n",
       "3  For a long long time I have found it difficult...    __label__not-distorted\n",
       "4  I’m sorry. I know it hurts. I know the pain of...    __label__not-distorted"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_other = copy.deepcopy(intersection_df)\n",
    "df_cat_other = df_cat_other[['text', 'label_new_2']]\n",
    "df_cat_other['label_new_2'] = df_cat_other['label_new_2'].apply(lambda x: '__label__' + x.replace(' ', '-').lower())\n",
    "df_cat_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df_cat_other['text']\n",
    "y_multi = df_cat_other['label_new_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_0 is 0.64\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.40      0.40      0.40         5\n",
      "   __label__not-distorted       0.80      0.80      0.80        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.64        22\n",
      "                macro avg       0.40      0.40      0.40        22\n",
      "             weighted avg       0.64      0.64      0.64        22\n",
      "\n",
      "F1_score weighted of a fold nr_1 is 0.59\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.50      0.20      0.29         5\n",
      "   __label__not-distorted       0.68      0.87      0.76        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.64        22\n",
      "                macro avg       0.39      0.36      0.35        22\n",
      "             weighted avg       0.58      0.64      0.59        22\n",
      "\n",
      "F1_score weighted of a fold nr_2 is 0.58\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.33      0.20      0.25         5\n",
      "   __label__not-distorted       0.68      0.87      0.76        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.64        22\n",
      "                macro avg       0.34      0.36      0.34        22\n",
      "             weighted avg       0.54      0.64      0.58        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ligren\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score weighted of a fold nr_3 is 0.73\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.50      0.50      0.50         4\n",
      "   __label__not-distorted       0.83      0.94      0.88        16\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.77        22\n",
      "                macro avg       0.44      0.48      0.46        22\n",
      "             weighted avg       0.70      0.77      0.73        22\n",
      "\n",
      "F1_score weighted of a fold nr_4 is 0.64\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.74      0.88      0.80        16\n",
      "__label__other-distortion       1.00      0.50      0.67         2\n",
      "\n",
      "                 accuracy                           0.68        22\n",
      "                macro avg       0.58      0.46      0.49        22\n",
      "             weighted avg       0.63      0.68      0.64        22\n",
      "\n",
      "F1_score weighted of a fold nr_5 is 0.64\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.71      1.00      0.83        15\n",
      "__label__other-distortion       1.00      0.33      0.50         3\n",
      "\n",
      "                 accuracy                           0.73        22\n",
      "                macro avg       0.57      0.44      0.44        22\n",
      "             weighted avg       0.62      0.73      0.64        22\n",
      "\n",
      "F1_score weighted of a fold nr_6 is 0.57\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.25      0.25      0.25         4\n",
      "   __label__not-distorted       0.73      0.73      0.73        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.57        21\n",
      "                macro avg       0.33      0.33      0.33        21\n",
      "             weighted avg       0.57      0.57      0.57        21\n",
      "\n",
      "F1_score weighted of a fold nr_7 is 0.65\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.33      0.50      0.40         4\n",
      "   __label__not-distorted       0.80      0.80      0.80        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.67        21\n",
      "                macro avg       0.38      0.43      0.40        21\n",
      "             weighted avg       0.63      0.67      0.65        21\n",
      "\n",
      "F1_score weighted of a fold nr_8 is 0.58\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.25      0.25      0.25         4\n",
      "   __label__not-distorted       0.71      0.80      0.75        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.62        21\n",
      "                macro avg       0.32      0.35      0.33        21\n",
      "             weighted avg       0.55      0.62      0.58        21\n",
      "\n",
      "F1_score weighted of a fold nr_9 is 0.56\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      " __label__catastrophizing       0.00      0.00      0.00         4\n",
      "   __label__not-distorted       0.72      0.87      0.79        15\n",
      "__label__other-distortion       0.00      0.00      0.00         2\n",
      "\n",
      "                 accuracy                           0.62        21\n",
      "                macro avg       0.24      0.29      0.26        21\n",
      "             weighted avg       0.52      0.62      0.56        21\n",
      "\n",
      "Max F1_score across folds is 0.7326203208556149 and mean score is 0.6177457346574994\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate splits\n",
    "f1_results = list()\n",
    "\n",
    "#counter for counting folds\n",
    "counter = 0\n",
    "\n",
    "for train_ix, test_ix in cv.split(X_multi,y_multi):\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
    "    y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
    "    \n",
    "    #prepare train data in a suitable format for fasttext\n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    train.to_csv('train_fasttext.txt', sep = '\\t', index = False, header = None, quoting=csv.QUOTE_NONE) #last parameter deletes unnecessary quote signs from text\n",
    "    \n",
    "    #train the model\n",
    "    model = fasttext.train_supervised(input = 'train_fasttext.txt', lr = 1.0, epoch = 15, dim = 300, pretrainedVectors='wiki-news-300d-1M-subword.vec')\n",
    "    \n",
    "    #create predictions\n",
    "    y_pred = X_test.apply(lambda x: model.predict(x)[0][0])\n",
    "    \n",
    "    #evaluate model by its F1-score and add into F1-score list\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1_score weighted of a fold nr_' + str(counter) + ' is ' + str(round(f1,2)))\n",
    "    f1_results.append(f1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    counter +=1\n",
    "\n",
    "print('Max F1_score across folds is ' + str(max(f1_results)) + ' and mean score is ' + str(mean(f1_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
