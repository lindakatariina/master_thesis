{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRARIES AND LOADING DATA"
      ],
      "metadata": {
        "id": "10ZeigzXF_DN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aDejsgYvehGt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import json\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.svm import SVC\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intersection_df = pd.read_json('intersection_df.json',  orient=\"records\", lines = True)"
      ],
      "metadata": {
        "id": "J-F7hczigDNk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "X = intersection_df['text']\n",
        "y = intersection_df['binary']"
      ],
      "metadata": {
        "id": "qAV0m5JnBuwG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BINARY SVM WITH NESTED STRATIFIED KFOLD CROSS-VALIDATION"
      ],
      "metadata": {
        "id": "Sxntwq6lGEWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#source: https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/?fbclid=IwAR0H80UxAb7r6cVgD2c5kAfqthfYBWOupzLwRk1Mg7l8BDcR9_EcASHHCsc\n",
        "#source: https://www.geeksforgeeks.org/stratified-k-fold-cross-validation/\n",
        "\n",
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer(max_features=500,min_df=3)), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "# configure the cross-validation procedure\n",
        "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# enumerate splits\n",
        "outer_results = list()\n",
        "for train_ix, test_ix in cv_outer.split(X,y):\n",
        "  # split data\n",
        "  X_train, X_test = X[train_ix], X[test_ix]\n",
        "  y_train, y_test = y[train_ix], y[test_ix]\n",
        "  # configure the cross-validation procedure\n",
        "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "  # define the model\n",
        "  model = pipeline\n",
        "  # define search space\n",
        "  space = dict()\n",
        "  #space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
        "  #space['vect__min_df'] = [1,3,5,10]\n",
        "  space['svc__C'] = [0.1, 1, 10, 100, 1000]\n",
        "  space['svc__gamma'] = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "  space['svc__kernel'] = ['linear', 'rbf']\n",
        "  # define search\n",
        "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
        "  # execute search\n",
        "  result = search.fit(X_train, y_train)\n",
        "  # get the best performing model fit on the whole training set\n",
        "  best_model = result.best_estimator_\n",
        "  # evaluate model on the hold out dataset\n",
        "  yhat = best_model.predict(X_test)\n",
        "  # evaluate the model\n",
        "  f1 = f1_score(y_test, yhat, average='weighted')\n",
        "  # store the result\n",
        "  outer_results.append(f1)\n",
        "  # report progress\n",
        "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
        "  print(classification_report(y_test, yhat))\n",
        "# summarize the estimated performance of the model\n",
        "print('\\n')\n",
        "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
        "print('Max F1-score weighted: ' + str(max(outer_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10HVUORjB5Rt",
        "outputId": "a5e6891e-5ff1-4aae-b43a-90cc691b3d54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.713, est=0.677, cfg={'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.87      0.81        15\n",
            "           1       0.60      0.43      0.50         7\n",
            "\n",
            "    accuracy                           0.73        22\n",
            "   macro avg       0.68      0.65      0.66        22\n",
            "weighted avg       0.71      0.73      0.71        22\n",
            "\n",
            ">f1score=0.689, est=0.700, cfg={'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.93      0.82        15\n",
            "           1       0.67      0.29      0.40         7\n",
            "\n",
            "    accuracy                           0.73        22\n",
            "   macro avg       0.70      0.61      0.61        22\n",
            "weighted avg       0.71      0.73      0.69        22\n",
            "\n",
            ">f1score=0.545, est=0.707, cfg={'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67        15\n",
            "           1       0.29      0.29      0.29         7\n",
            "\n",
            "    accuracy                           0.55        22\n",
            "   macro avg       0.48      0.48      0.48        22\n",
            "weighted avg       0.55      0.55      0.55        22\n",
            "\n",
            ">f1score=0.653, est=0.692, cfg={'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79        15\n",
            "           1       0.50      0.29      0.36         7\n",
            "\n",
            "    accuracy                           0.68        22\n",
            "   macro avg       0.61      0.58      0.58        22\n",
            "weighted avg       0.65      0.68      0.65        22\n",
            "\n",
            ">f1score=0.540, est=0.720, cfg={'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.81      0.74        16\n",
            "           1       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.59        22\n",
            "   macro avg       0.34      0.41      0.37        22\n",
            "weighted avg       0.50      0.59      0.54        22\n",
            "\n",
            ">f1score=0.636, est=0.700, cfg={'svc__C': 1000, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.75      0.75        16\n",
            "           1       0.33      0.33      0.33         6\n",
            "\n",
            "    accuracy                           0.64        22\n",
            "   macro avg       0.54      0.54      0.54        22\n",
            "weighted avg       0.64      0.64      0.64        22\n",
            "\n",
            ">f1score=0.840, est=0.667, cfg={'svc__C': 10, 'svc__gamma': 1, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        15\n",
            "           1       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.86        21\n",
            "   macro avg       0.92      0.75      0.79        21\n",
            "weighted avg       0.88      0.86      0.84        21\n",
            "\n",
            ">f1score=0.695, est=0.686, cfg={'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.87      0.81        15\n",
            "           1       0.50      0.33      0.40         6\n",
            "\n",
            "    accuracy                           0.71        21\n",
            "   macro avg       0.63      0.60      0.61        21\n",
            "weighted avg       0.69      0.71      0.69        21\n",
            "\n",
            ">f1score=0.626, est=0.669, cfg={'svc__C': 1000, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79        15\n",
            "           1       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.67        21\n",
            "   macro avg       0.53      0.52      0.51        21\n",
            "weighted avg       0.61      0.67      0.63        21\n",
            "\n",
            ">f1score=0.626, est=0.667, cfg={'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79        15\n",
            "           1       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.67        21\n",
            "   macro avg       0.53      0.52      0.51        21\n",
            "weighted avg       0.61      0.67      0.63        21\n",
            "\n",
            "\n",
            "\n",
            "F1-score weighted Mean and Std: 0.656 (0.082)\n",
            "Max F1-score weighted: 0.8398268398268398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MULTI-CLASS CLASSIFICATION"
      ],
      "metadata": {
        "id": "yB4BkJoDGIma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catastrophizing vs Other distortion vs Labeling"
      ],
      "metadata": {
        "id": "Ue6PGBTEHP9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intersection_df['label_new'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaAQRBClHTB_",
        "outputId": "e2012da5-1b97-4eb9-c5a1-10e33238a0cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not Distorted       152\n",
              "Catastrophizing      43\n",
              "Other distortion     12\n",
              "Labeling              9\n",
              "Name: label_new, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_distortions = intersection_df[intersection_df['binary'] == 1]\n",
        "df_with_distortions = df_with_distortions.reset_index(drop=True)\n",
        "df_with_distortions['label_new'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDnjC6yIHXh2",
        "outputId": "e6865334-eb88-4a49-b881-34b1ad114e76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Catastrophizing     43\n",
              "Other distortion    12\n",
              "Labeling             9\n",
              "Name: label_new, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_multi = df_with_distortions['text']\n",
        "y_multi = df_with_distortions['label_new']"
      ],
      "metadata": {
        "id": "3Zl2mlYdHZiq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "# configure the cross-validation procedure\n",
        "cv_outer = StratifiedKFold(n_splits=9, shuffle=True, random_state=1)\n",
        "# enumerate splits\n",
        "outer_results = list()\n",
        "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
        "  # split data\n",
        "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
        "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
        "  # configure the cross-validation procedure\n",
        "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "  # define the model\n",
        "  model = pipeline\n",
        "  # define search space\n",
        "  space = dict()\n",
        "  space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
        "  space['vect__min_df'] = [1,3,5,10]\n",
        "  space['svc__C'] = [0.1, 1, 10, 100, 1000]\n",
        "  space['svc__gamma'] = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "  space['svc__kernel'] = ['linear', 'rbf']\n",
        "  # define search\n",
        "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
        "  # execute search\n",
        "  result = search.fit(X_train, y_train)\n",
        "  # get the best performing model fit on the whole training set\n",
        "  best_model = result.best_estimator_\n",
        "  # evaluate model on the hold out dataset\n",
        "  yhat = best_model.predict(X_test)\n",
        "  # evaluate the model\n",
        "  f1 = f1_score(y_test, yhat, average='weighted')\n",
        "  # store the result\n",
        "  outer_results.append(f1)\n",
        "  # report progress\n",
        "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
        "  print(classification_report(y_test, yhat))\n",
        "# summarize the estimated performance of the model\n",
        "print('\\n')\n",
        "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
        "print('Max F1-score weighted: ' + str(max(outer_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EToLYyWl0JH",
        "outputId": "735b1b81-a46d-400f-e9ab-4666ddc28b6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.621, est=0.597, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      0.80      0.73         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       1.00      0.50      0.67         2\n",
            "\n",
            "        accuracy                           0.62         8\n",
            "       macro avg       0.56      0.43      0.46         8\n",
            "    weighted avg       0.67      0.62      0.62         8\n",
            "\n",
            ">f1score=0.429, est=0.590, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.60      0.60      0.60         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.00      0.00      0.00         1\n",
            "\n",
            "        accuracy                           0.43         7\n",
            "       macro avg       0.20      0.20      0.20         7\n",
            "    weighted avg       0.43      0.43      0.43         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.792, est=0.600, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.83      1.00      0.91         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       1.00      1.00      1.00         1\n",
            "\n",
            "        accuracy                           0.86         7\n",
            "       macro avg       0.61      0.67      0.64         7\n",
            "    weighted avg       0.74      0.86      0.79         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.571, est=0.603, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.80      0.80      0.80         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.00      0.00      0.00         1\n",
            "\n",
            "        accuracy                           0.57         7\n",
            "       macro avg       0.27      0.27      0.27         7\n",
            "    weighted avg       0.57      0.57      0.57         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.667, est=0.595, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.80      0.80      0.80         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.50      1.00      0.67         1\n",
            "\n",
            "        accuracy                           0.71         7\n",
            "       macro avg       0.43      0.60      0.49         7\n",
            "    weighted avg       0.64      0.71      0.67         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.635, est=0.605, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       1.00      0.80      0.89         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.00      0.00      0.00         1\n",
            "\n",
            "        accuracy                           0.57         7\n",
            "       macro avg       0.33      0.27      0.30         7\n",
            "    weighted avg       0.71      0.57      0.63         7\n",
            "\n",
            ">f1score=0.595, est=0.590, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.71      1.00      0.83         5\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.00      0.00      0.00         1\n",
            "\n",
            "        accuracy                           0.71         7\n",
            "       macro avg       0.24      0.33      0.28         7\n",
            "    weighted avg       0.51      0.71      0.60         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.648, est=0.687, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      1.00      0.80         4\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       1.00      0.50      0.67         2\n",
            "\n",
            "        accuracy                           0.71         7\n",
            "       macro avg       0.56      0.50      0.49         7\n",
            "    weighted avg       0.67      0.71      0.65         7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.416, est=0.620, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.57      1.00      0.73         4\n",
            "        Labeling       0.00      0.00      0.00         1\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.57         7\n",
            "       macro avg       0.19      0.33      0.24         7\n",
            "    weighted avg       0.33      0.57      0.42         7\n",
            "\n",
            "\n",
            "\n",
            "F1-score weighted Mean and Std: 0.597 (0.110)\n",
            "Max F1-score weighted: 0.7922077922077921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catastrophizing vs Other vs Not distorted"
      ],
      "metadata": {
        "id": "nOV2vUG0Kqr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intersection_df['label_new_2'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzSmb9jbKvAk",
        "outputId": "5ca50c29-ba52-4278-c481-aac14ecd6950"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not Distorted       152\n",
              "Catastrophizing      43\n",
              "Other distortion     21\n",
              "Name: label_new_2, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_multi = intersection_df['text']\n",
        "y_multi = intersection_df['label_new_2']"
      ],
      "metadata": {
        "id": "Ha83jRh0KxOK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "# configure the cross-validation procedure\n",
        "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# enumerate splits\n",
        "outer_results = list()\n",
        "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
        "  # split data\n",
        "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
        "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
        "  # configure the cross-validation procedure\n",
        "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "  # define the model\n",
        "  model = pipeline\n",
        "  # define search space\n",
        "  space = dict()\n",
        "  space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
        "  space['vect__min_df'] = [1,3,5,10]\n",
        "  space['svc__C'] = [0.1, 1, 10, 100, 1000]\n",
        "  space['svc__gamma'] = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "  space['svc__kernel'] = ['linear', 'rbf']\n",
        "  # define search\n",
        "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
        "  # execute search\n",
        "  result = search.fit(X_train, y_train)\n",
        "  # get the best performing model fit on the whole training set\n",
        "  best_model = result.best_estimator_\n",
        "  # evaluate model on the hold out dataset\n",
        "  yhat = best_model.predict(X_test)\n",
        "  # evaluate the model\n",
        "  f1 = f1_score(y_test, yhat, average='weighted')\n",
        "  # store the result\n",
        "  outer_results.append(f1)\n",
        "  # report progress\n",
        "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
        "  print(classification_report(y_test, yhat))\n",
        "# summarize the estimated performance of the model\n",
        "print('\\n')\n",
        "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
        "print('Max F1-score weighted: ' + str(max(outer_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OYNni62Kz3V",
        "outputId": "7a98b75d-3517-4ac7-e5b0-f84cc78ef06e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.553, est=0.638, cfg={'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 2000, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.00      0.00      0.00         5\n",
            "   Not Distorted       0.68      1.00      0.81        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.68        22\n",
            "       macro avg       0.23      0.33      0.27        22\n",
            "    weighted avg       0.46      0.68      0.55        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.506, est=0.680, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 1000, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.00      0.00      0.00         5\n",
            "   Not Distorted       0.65      0.87      0.74        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.59        22\n",
            "       macro avg       0.22      0.29      0.25        22\n",
            "    weighted avg       0.44      0.59      0.51        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.610, est=0.645, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 500, 'vect__min_df': 3}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.50      0.20      0.29         5\n",
            "   Not Distorted       0.70      0.93      0.80        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.68        22\n",
            "       macro avg       0.40      0.38      0.36        22\n",
            "    weighted avg       0.59      0.68      0.61        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.769, est=0.645, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 2000, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      0.50      0.57         4\n",
            "   Not Distorted       0.84      1.00      0.91        16\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.82        22\n",
            "       macro avg       0.50      0.50      0.50        22\n",
            "    weighted avg       0.73      0.82      0.77        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.590, est=0.666, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 2000, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.00      0.00      0.00         4\n",
            "   Not Distorted       0.71      0.94      0.81        16\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.68        22\n",
            "       macro avg       0.24      0.31      0.27        22\n",
            "    weighted avg       0.52      0.68      0.59        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.614, est=0.679, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 3}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.00      0.00      0.00         4\n",
            "   Not Distorted       0.70      0.93      0.80        15\n",
            "Other distortion       1.00      0.33      0.50         3\n",
            "\n",
            "        accuracy                           0.68        22\n",
            "       macro avg       0.57      0.42      0.43        22\n",
            "    weighted avg       0.61      0.68      0.61        22\n",
            "\n",
            ">f1score=0.594, est=0.624, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.17      0.25      0.20         4\n",
            "   Not Distorted       0.71      0.67      0.69        15\n",
            "Other distortion       1.00      0.50      0.67         2\n",
            "\n",
            "        accuracy                           0.57        21\n",
            "       macro avg       0.63      0.47      0.52        21\n",
            "    weighted avg       0.64      0.57      0.59        21\n",
            "\n",
            ">f1score=0.618, est=0.608, cfg={'svc__C': 1000, 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'vect__max_features': 500, 'vect__min_df': 3}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.33      0.50      0.40         4\n",
            "   Not Distorted       0.79      0.73      0.76        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.62        21\n",
            "       macro avg       0.37      0.41      0.39        21\n",
            "    weighted avg       0.62      0.62      0.62        21\n",
            "\n",
            ">f1score=0.726, est=0.662, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.60      0.75      0.67         4\n",
            "   Not Distorted       0.81      0.87      0.84        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.76        21\n",
            "       macro avg       0.47      0.54      0.50        21\n",
            "    weighted avg       0.69      0.76      0.73        21\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.588, est=0.638, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 2000, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.00      0.00      0.00         4\n",
            "   Not Distorted       0.74      0.93      0.82        15\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.67        21\n",
            "       macro avg       0.25      0.31      0.27        21\n",
            "    weighted avg       0.53      0.67      0.59        21\n",
            "\n",
            "\n",
            "\n",
            "F1-score weighted Mean and Std: 0.617 (0.073)\n",
            "Max F1-score weighted: 0.7688311688311689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BINARY - Catastrophizing vs Other"
      ],
      "metadata": {
        "id": "hYXyKp9KPzbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_multi = df_with_distortions['text']\n",
        "y_multi = df_with_distortions['label_new_2']"
      ],
      "metadata": {
        "id": "g1Qmz2RmP2fb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_multi.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqUD4wARP42h",
        "outputId": "4557ec17-32a9-45c3-b9c3-c5564d8cb1ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Catastrophizing     43\n",
              "Other distortion    21\n",
              "Name: label_new_2, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "                  ('vect', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('svc', SVC(random_state = 1))\n",
        "                  ])\n",
        "\n",
        "# configure the cross-validation procedure\n",
        "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# enumerate splits\n",
        "outer_results = list()\n",
        "for train_ix, test_ix in cv_outer.split(X_multi,y_multi):\n",
        "  # split data\n",
        "  X_train, X_test = X_multi[train_ix], X_multi[test_ix]\n",
        "  y_train, y_test = y_multi[train_ix], y_multi[test_ix]\n",
        "  # configure the cross-validation procedure\n",
        "  cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "  # define the model\n",
        "  model = pipeline\n",
        "  # define search space\n",
        "  space = dict()\n",
        "  space['vect__max_features'] = [5000,4000,3000,2000,1000,500,5]\n",
        "  space['vect__min_df'] = [1,3,5,10]\n",
        "  space['svc__C'] = [0.1, 1, 10, 100, 1000]\n",
        "  space['svc__gamma'] = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "  space['svc__kernel'] = ['linear', 'rbf']\n",
        "  # define search\n",
        "  search = GridSearchCV(model, space, scoring='f1_weighted', cv=cv_inner, refit=True)\n",
        "  # execute search\n",
        "  result = search.fit(X_train, y_train)\n",
        "  # get the best performing model fit on the whole training set\n",
        "  best_model = result.best_estimator_\n",
        "  # evaluate model on the hold out dataset\n",
        "  yhat = best_model.predict(X_test)\n",
        "  # evaluate the model\n",
        "  f1 = f1_score(y_test, yhat, average='weighted')\n",
        "  # store the result\n",
        "  outer_results.append(f1)\n",
        "  # report progress\n",
        "  print('>f1score=%.3f, est=%.3f, cfg=%s' % (f1, result.best_score_, result.best_params_))\n",
        "  print(classification_report(y_test, yhat))\n",
        "# summarize the estimated performance of the model\n",
        "print('\\n')\n",
        "print('F1-score weighted Mean and Std: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
        "print('Max F1-score weighted: ' + str(max(outer_results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIb23lEfP5tc",
        "outputId": "cce3eb3f-7194-4028-ba1e-361e7ba58bd0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.429, est=0.689, cfg={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.60      0.60      0.60         5\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.43         7\n",
            "       macro avg       0.30      0.30      0.30         7\n",
            "    weighted avg       0.43      0.43      0.43         7\n",
            "\n",
            ">f1score=0.519, est=0.735, cfg={'svc__C': 1000, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'vect__max_features': 5, 'vect__min_df': 1}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      0.80      0.73         5\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.57         7\n",
            "       macro avg       0.33      0.40      0.36         7\n",
            "    weighted avg       0.48      0.57      0.52         7\n",
            "\n",
            ">f1score=1.000, est=0.709, cfg={'svc__C': 100, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       1.00      1.00      1.00         5\n",
            "Other distortion       1.00      1.00      1.00         2\n",
            "\n",
            "        accuracy                           1.00         7\n",
            "       macro avg       1.00      1.00      1.00         7\n",
            "    weighted avg       1.00      1.00      1.00         7\n",
            "\n",
            ">f1score=0.343, est=0.661, cfg={'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.50      0.75      0.60         4\n",
            "Other distortion       0.00      0.00      0.00         3\n",
            "\n",
            "        accuracy                           0.43         7\n",
            "       macro avg       0.25      0.38      0.30         7\n",
            "    weighted avg       0.29      0.43      0.34         7\n",
            "\n",
            ">f1score=0.514, est=0.677, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      0.50      0.57         4\n",
            "Other distortion       0.33      0.50      0.40         2\n",
            "\n",
            "        accuracy                           0.50         6\n",
            "       macro avg       0.50      0.50      0.49         6\n",
            "    weighted avg       0.56      0.50      0.51         6\n",
            "\n",
            ">f1score=0.533, est=0.676, cfg={'svc__C': 10, 'svc__gamma': 1, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      1.00      0.80         4\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.67         6\n",
            "       macro avg       0.33      0.50      0.40         6\n",
            "    weighted avg       0.44      0.67      0.53         6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">f1score=0.667, est=0.709, cfg={'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.75      0.75      0.75         4\n",
            "Other distortion       0.50      0.50      0.50         2\n",
            "\n",
            "        accuracy                           0.67         6\n",
            "       macro avg       0.62      0.62      0.62         6\n",
            "    weighted avg       0.67      0.67      0.67         6\n",
            "\n",
            ">f1score=1.000, est=0.704, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       1.00      1.00      1.00         4\n",
            "Other distortion       1.00      1.00      1.00         2\n",
            "\n",
            "        accuracy                           1.00         6\n",
            "       macro avg       1.00      1.00      1.00         6\n",
            "    weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            ">f1score=0.815, est=0.682, cfg={'svc__C': 10, 'svc__gamma': 1000, 'svc__kernel': 'linear', 'vect__max_features': 5000, 'vect__min_df': 10}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.80      1.00      0.89         4\n",
            "Other distortion       1.00      0.50      0.67         2\n",
            "\n",
            "        accuracy                           0.83         6\n",
            "       macro avg       0.90      0.75      0.78         6\n",
            "    weighted avg       0.87      0.83      0.81         6\n",
            "\n",
            ">f1score=0.533, est=0.688, cfg={'svc__C': 10, 'svc__gamma': 1, 'svc__kernel': 'rbf', 'vect__max_features': 5, 'vect__min_df': 3}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Catastrophizing       0.67      1.00      0.80         4\n",
            "Other distortion       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.67         6\n",
            "       macro avg       0.33      0.50      0.40         6\n",
            "    weighted avg       0.44      0.67      0.53         6\n",
            "\n",
            "\n",
            "\n",
            "F1-score weighted Mean and Std: 0.635 (0.218)\n",
            "Max F1-score weighted: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Uus - SVM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}